{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "<center><h1><br><font color=\"blue\">Serve Machine Learning Predictions over the Web using Amazon Web Services and Chalice.</font></h1></center>\n",
    "    <ol>\n",
    "        <li><a href=\"#objective1\">Making Predictions Over the Web using Serverless Computing.</a></li><br>\n",
    "        <li><a href=\"#objective2\">Project Description and Natural Language Processing in Machine Learning.</a></li><br>\n",
    "        <li><a href=\"#objective3\">Demonstrate how to load, examine and transform data in AWS.</a></li><br>   \n",
    "        <li><a href=\"#objective4\">Demonstrate how to train the machine learning model.</a></li><br>\n",
    "        <li><a href=\"#objective5\">Demonstrate how to host and test the model over the cloud.</a></li><br>\n",
    "        <li><a href=\"#objective6\">Demonstrate how to set up serverless API endpoint.</a></li><br>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"objective1\" style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "<center><h1><br><font color=\"blue\">Making Predictions Over the Web using Serverless Computing.</font></h1></center>\n",
    "    <hr>\n",
    "    <ul><h4>Serverless Computing</h4>\n",
    "        <li>Is a cloud computing execution model whereby a company allocates machine resources to a customer, taking care of their server needs while the customer pays on demand.</li>\n",
    "        <li>Servers are used hardware and software that provide functionality for other programs and devices. This includes sharing data and performing computations.  There are various server types, and managing these resources is taxing.</li>\n",
    "        <li>Serverless computing is a new model, whereby companies no longer need to purchase and manage their own servers, instead, they can use another companies servers to carry out their work.</li>\n",
    "        <li>Serverless computing has enabled developers to create web applications without needed to manage their own servers. With serverless computing, developers send their code or executable package to be executed by the the serverless platform provider.</li>\n",
    "        <li>AWS introduced their own serverless architecture called <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/welcome.html\">Lambda Services</a> </li>\n",
    "        <li>Lambda Services allows developes to execute their code in a particular runtime environment.</li>\n",
    "        <li>This is expecially true when trying to connect a Machine Learning application to the web. Lambda Services makes it easy to interface with Amazon SageMaker.</li>\n",
    "        <li><mark style= \"background-color: yellow;\">The aim of this project is to demonstrate how to carry out serverless computing using AWS Chalice.</mark></li>\n",
    "    </ul>  \n",
    "    <hr>\n",
    "    <ul><h4>AWS Chalice</h4>\n",
    "        <li><a href=\"https://chalice.readthedocs.io/en/stable/\">Chalice</a> is a python serverless microframework developed by AWS.</li>\n",
    "        <li>Chalice enables developers to quickly prepare and deploy a working serverless app that can scale according to the its AWS lambda needs.</li>\n",
    "        <li>Chalice is inspired by the common python web framework <a href=\"https://www.fullstackpython.com/flask.html\">Flask</a>.</li>\n",
    "        <li>The advantage of chalice is that it interfaces with AWS and it takes a minimalistic approach.</li>\n",
    "        <li>The following steps will go through the steps needed to build and deploy a simple web application using Chalice</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"objective2\" style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "    <center><h1><strong>Project Description and Natural Language Processing in Machine Learning.</strong></h1></center>\n",
    "    <ul>\n",
    "        <li><mark>Case Study</mark>: In this project, a business want to improve how it handles online customer service requests made via tweets.  Don't ask me why this was a thing, but it was.  This business would have their staff read the tweets and make judgement calls on whether the tweet should be escalated to a human response, or directed to an automated service.  This is obviously subjective and labor intensive, thus, <mark>the goal</mark> of this project is to automate this as much as possible, and use natural language processing to triage the customers based on the text in their tweet.</li><br>\n",
    "        <li><mark>Objective</mark>: Deciding whether to escalate a customer support issue.</li><br>  \n",
    "        <li><mark>Data</mark>: The <a href=\"www.kaggle.com/thoughtvector/customer-support-on-twitter/\">dataset</a> was modified from the Customer Support on Twitter dataset.  This dataset contains 3 million tweets and 6 features, and the dataset is commonly used to aid in natural language understanding and in this example, for the study of customer support.</li><br>\n",
    "        <li><mark>Target feature</mark>: The feature that will be used to build a prediction model is the `escalate` feature.  This is a binary column that contains information on whether staff from the company responded to the tweeter with human invervention, or an automated response.</li><br>\n",
    "        <li><mark>Method</mark>: Natural language process will be used to apply a mathematical algorithm to the text in each tweet and builds a model for those tweets that are escalated, and those that are not.  This model can then be applied to new tweets and classify them mathematically as either 'to escalate' or to 'not escalate'. <strong>BlazingText</strong> natural language processing algorithm will be used in this project and is described below.</li><br>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"objective3\" style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "    <center><h1><strong>Demonstrate how to load, examine and transform data in AWS.</strong></h1></center>\n",
    "    <ul>\n",
    "        <li><strong>Overview:</strong>\n",
    "            <ol>\n",
    "                <li>Prepare for AWS S3 Data Connection</li>\n",
    "                <li>Import Dependencies</li>\n",
    "                <li>Assign SageMaker Role</li>\n",
    "                <li>Establish a connection with S3</li>\n",
    "                <li>Load data into pandas dataframe</li>\n",
    "                <li>Inspect data</li>\n",
    "                <li>Split data for training and validation</li>\n",
    "                <li>Transform data to format used by BlazingText</li>\n",
    "            </ol>\n",
    "        </li><br>     \n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Prepare for AWS S3 Data Connection</h2>\n",
    "\n",
    " - Assign your bucket details into variables\n",
    " - Buckets in AWS are a file directory system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket = \"mlbuisness-project-data\"\n",
    "subfolder = 'ch04'\n",
    "dataset = 'data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Import Dependencies</h2>\n",
    "\n",
    "<ul>\n",
    "    <li><font style=\"text-decoration: underline;\" color=\"red\">These dependencies will be executed in the Amazon SageMaker notebook instance, and if they are not already installed in this environment, you will need to do so in the notebook.</font></li>\n",
    "    <li><strong><code><a href=\"https://pandas.pydata.org/pandas-docs/stable/index.html\">pandas</a> as pd</code></strong>: is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.</li>\n",
    "    <li><strong><code><a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\">boto3</a></code></strong>: You use the AWS SDK for Python (Boto3) to create, configure, and manage AWS services, such as Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Simple Storage Service (Amazon S3). The SDK provides an object-oriented API as well as low-level access to AWS services.</li>\n",
    "    <li><strong><code><a href=\"https://sagemaker.readthedocs.io/en/stable/\">sagemaker</a></code></strong>: Amazon SageMaker Python SDK is an open source library for training and deploying machine-learned models on Amazon SageMaker.\n",
    "\n",
    "</li>\n",
    "    <li><strong><code><a href=\"https://pypi.org/project/s3fs/\">s3fs</a></code></strong>: S3FS builds on botocore to provide a convenient Python filesystem interface for S3.</li>\n",
    "    <li><strong><code><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">sklearn.model_selection, train_test_split</a></code></strong>: Split arrays or matrices into random train and test subsets</li>\n",
    "    <li><strong><code><a href=\"https://docs.python.org/3/library/json.html#basic-usage\">json</a></code></strong>: is a lightweight data interchange format inspired by JavaScript object literal syntax. Converts data to and from json format.</li>\n",
    "    <li><strong><code><a href=\"https://docs.python.org/3/library/csv.html\">csv</a></code></strong>: The csv module implements classes to read and write tabular data in CSV format.</li>\n",
    "    <li><strong><code><a href=\"https://pypi.org/project/python-slugify/\">slugify</a></code></strong>: A Python Slugify application that handles Unicode and is commonly used to turn text into website URLs. It also provides a  mechanism to normalize text, and will allow our tweet data to be accessed as URLs. <font style=\"text-decoration: underline;\" color=\"red\">You may need to pip install this dependency directly into your amazon sagemaker notebook.</font></li>\n",
    "    <li><strong><code><a href=\"https://docs.python.org/3/library/time.html\">time</a></code></strong>: module that provides time-related functions. The <code>slee</code> function suspend execution of the calling thread for the given number of seconds stated in its parameter.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import s3fs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from slugify import slugify\n",
    "import csv\n",
    "from time import sleep\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "s3 = s3fs.S3FileSystem(anon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Assign SageMaker Role and 4. Establish a connection with S3</h2>\n",
    "\n",
    " - <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-ex-role.html\">`sagemaker.get_execution_role()`</a>: This code will get the execution role for the notebook instance. This is the IAM role that you created for your notebook instance. You pass the role to the tuning job. (This is the access priviledges)\n",
    " - <a ref=\"https://s3fs.readthedocs.io/en/latest/\">`s3 = s3fs.S3FileSystem(anon=False)`</a>: Code will provide access to all buckets you have with your credentials and saves it to the variable s3. The s3 is used as part of the string to get the files in S3 needed to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to S3\n",
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=data_bucket, Prefix=subfolder)['Contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Load data into pandas dataframe and 6. Inspect data</h2>\n",
    "\n",
    " - `pd.read_csv()`: this code uses the standard pandas function `read_csv()` to open a csv file. \n",
    " - `(f's3://{data_bucket}/{subfolder}/{dataset}', low_memory=False)` is the AWS S3 filepath to the actual CSV file we have saved. \n",
    " - The variable `s3` was saved in the previous step and is the AWS root directory\n",
    " - `{data_bucket}/{subfolder}/{dataset}` is the absolute path to the file. Those variables were saved in part 1 of this post.\n",
    " - `display(df.head())`: the `display()` function is a IPython.display module that runs the appropriate dunder method to get the appropriate data to display. \n",
    " - The parameter `df.head()` will show the top 5 rows of data in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to</th>\n",
       "      <th>text</th>\n",
       "      <th>escalate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>115713</td>\n",
       "      <td>Tue Oct 31 20:00:43 +0000 2017</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcare Since I signed up with you....Sinc...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>115716</td>\n",
       "      <td>Tue Oct 31 22:16:48 +0000 2017</td>\n",
       "      <td>Ask_Spectrum</td>\n",
       "      <td>@Ask_Spectrum Would you like me to email you a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  author_id                      created_at   in_reply_to  \\\n",
       "0         2     115712  Tue Oct 31 22:11:45 +0000 2017    sprintcare   \n",
       "1         3     115712  Tue Oct 31 22:08:27 +0000 2017    sprintcare   \n",
       "2         5     115712  Tue Oct 31 21:49:35 +0000 2017    sprintcare   \n",
       "3        16     115713  Tue Oct 31 20:00:43 +0000 2017    sprintcare   \n",
       "4        22     115716  Tue Oct 31 22:16:48 +0000 2017  Ask_Spectrum   \n",
       "\n",
       "                                                text escalate  \n",
       "0      @sprintcare and how do you propose we do that    False  \n",
       "1  @sprintcare I have sent several private messag...     True  \n",
       "2                                 @sprintcare I did.    False  \n",
       "3  @sprintcare Since I signed up with you....Sinc...    False  \n",
       "4  @Ask_Spectrum Would you like me to email you a...    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.75 s, sys: 179 ms, total: 1.93 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(f's3://{data_bucket}/{subfolder}/{dataset}', low_memory=False)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 500821\n",
      "False    401761\n",
      "True      99059\n",
      "Name: escalate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows in dataset: {df.shape[0]}')\n",
    "print(df['escalate'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>7. Split data for training and validation</h2>\n",
    "\n",
    " - <a href'https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">`train_test_split`</a> will split the data into subsets.\n",
    " - `train_df, val_df, _, _ ` are the variables that are assigned to the subsets that are split. Only two are needed, the training and validation sets, while the y_train, y_test are ignored, as underscores are used instead.  The `_` indicates that part of a function result is being deliberately ignored.\n",
    " - `(df,df['escalate'], test_size = 0.2, random_state = 0)`:\n",
    "   - `df` are all the features in this study\n",
    "   - `df['escalate']`: is the target feature (if a customer was helped by a human or by an automated system)\n",
    "   - `test_size = 0.2`: this will indicate the proportion of the dataset to include in the test split. Default it is 0.25.\n",
    "   - `random_state = 0`: Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls. Zero means to ignore and not shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400656 rows in training data\n",
      "100165 rows in validation data\n"
     ]
    }
   ],
   "source": [
    "format for BlazingTexttrain_df, val_df, _, _ = train_test_split(df, df['escalate'], test_size=0.2, random_state=0)\n",
    "print(f'{train_df.shape[0]} rows in training data')\n",
    "print(f'{val_df.shape[0]} rows in validation data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>8. Transform data to format used by BlazingText</h2>\n",
    "\n",
    " - The objective at this point is to prepare the data for the BlazingText algorithm\n",
    " - BlazingText requires that the label have a specific format, followed by the tokenized text that will be analyzed.\n",
    " - Tokenization is the process of breaking text into parts that are linguistically meaningful.\n",
    " - Tokenization is done using the <code>NLTK</code> library.\n",
    " - This process needs to be done for the entire dataset, so the following two functions will prepare, tokenize, and return the data in the format for BlazingText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-decoration: underline;\">Preprocess function</h3>\n",
    "\n",
    "<strong>What this does:</strong> this function will turn each instance in the dataframe (either the validation or the training dataset) and convert it into individual lists. The lists will then be passed onto the <code>transform_instance()</code> function, which will transform the data we need for BlazingText. The new formatted data will then be added to a new dataframe, called <code>transformed_df</code>.\n",
    "\n",
    " - Step 1: Convert each instance (row) in the dataset into a list\n",
    " - Step 2: Uses a <code>map()</code> function, which will apply the <code>transform_instances()</code> function to each list that was made in step 1.\n",
    " - Step 3: Each new list returned from <code>transform_instances()</code> is added to a new dataframe.\n",
    " - Step 4: Once all the data is converted, the new <code>transformed_df</code> is returned for use in the training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-decoration: underline;\">Transform Instances Function</h3>\n",
    "\n",
    "<strong>What this does:</strong> This will take a row of data (the tweet id, the author id, the created at, the tweet, and the escalate data) and get the tweet and escalate data, manipulate it, and return it so that it can be added to a new dataframe that will be used for model training.\n",
    "\n",
    " - Step 1: Create an empty list that will hold the label and tokenized tweet\n",
    " - Step 2: Get the fifth element of each instance (this is the escalate label), and if it is true, label it <code>__label__1</code> or <code>__label__0</code> if it is false.\n",
    " - Step 3: Add the new label to the new list\n",
    " - Step 4a: Tokenize the 4th element of the instance (which is the customer tweet asking for help)\n",
    " - Step 4b: Before the tweet is tokenized, the tweet is lower cased (you know some of the customer angry and typing in all caps lol). \n",
    " - Step 4c: The tokenized tweet is then added to the new label created in step 2\n",
    " - Step 5: Return the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0 alaskaair done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0 tesco have sent dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1 glocare am not d only one your netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0 181643 amazonhelp ask for confirmed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__0 gwrhelp 120658 thanks josh not yet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                          __label__0 alaskaair done\n",
       "1                      __label__0 tesco have sent dm\n",
       "2  __label__1 glocare am not d only one your netw...\n",
       "3  __label__0 181643 amazonhelp ask for confirmed...\n",
       "4  __label__0 gwrhelp 120658 thanks josh not yet ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.54 s, sys: 3.84 ms, total: 4.55 s\n",
      "Wall time: 4.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def preprocess(df):\n",
    "    all_rows = df.values.tolist()\n",
    "    transformed_rows = list(map(transform_instance, all_rows))\n",
    "    transformed_df = pd.DataFrame(transformed_rows)\n",
    "    return transformed_df\n",
    "\n",
    "def transform_instance(row):\n",
    "    text = slugify(row[4], separator=' ')\n",
    "    cur_row = []\n",
    "    label = \"__label__1\" if row[5] == True else \"__label__0\" # Prefix 0 or 1 from sentiment\n",
    "    cur_row.append(label)\n",
    "    cur_row.append(text)\n",
    "    return ' '.join(cur_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing, Transforming and Saving Validation Data for BlazingText</h3>\n",
    "\n",
    " - `transformed_validation_rows = preprocess(val_df)`: transforms the validation data for use in model\n",
    " - `display(transformed_validation_rows.head())`: inspect transformation\n",
    " - `1s3_validation_data = f's3://{data_bucket}/{subfolder}/processed/validation.csv'`: saves a csv file names validation.csv in directory\n",
    " - `data = transformed_validation_rows.to_csv(....)`: saves the data into the csv file in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_validation_rows = preprocess(val_df)\n",
    "display(transformed_validation_rows.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_validation_data = f's3://{data_bucket}/{subfolder}/processed/validation.csv'\n",
    "\n",
    "data = transformed_validation_rows.to_csv(\n",
    "        header=False, index=False, quoting=csv.QUOTE_NONE, sep='|', escapechar='^').encode()\n",
    "with s3.open(s3_validation_data, 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing, Transforming and Saving Training Data for BlazingText</h3>\n",
    "\n",
    " - `transformed_validation_rows = preprocess(train_df)`: transforms the validation data for use in model\n",
    " - `display(transformed_validation_rows.head())`: inspect transformation\n",
    " - `s3_train_data = f's3://{data_bucket}/{subfolder}/processed/validation.csv'`: saves a csv file names validation.csv in directory\n",
    " - `data = transformed_train_rows.to_csv(....)`: saves the data into the csv file in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0 sainsburys what bit do you need to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0 amazonhelp hi there thanks for gett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0 applesupport yes and yes started ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0 spotifycares https t co daey7wkhfq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__0 applesupport https t co lkcy88blnw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  __label__0 sainsburys what bit do you need to ...\n",
       "1  __label__0 amazonhelp hi there thanks for gett...\n",
       "2  __label__0 applesupport yes and yes started ye...\n",
       "3      __label__0 spotifycares https t co daey7wkhfq\n",
       "4      __label__0 applesupport https t co lkcy88blnw"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 s, sys: 185 ms, total: 19.5 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transformed_train_rows = preprocess(train_df)\n",
    "display(transformed_train_rows.head())\n",
    "\n",
    "s3_train_data = f's3://{data_bucket}/{subfolder}/processed/train.csv'\n",
    "\n",
    "data = transformed_train_rows.to_csv(\n",
    "        header=False, index=False, quoting=csv.QUOTE_NONE, sep='|', escapechar='^').encode()\n",
    "with s3.open(s3_train_data, 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare Training and Validation Datasets</h3>\n",
    "\n",
    " - `sagemaker.inputs.TrainingInput(s3_data, distribution, content_type, s3_data_type)`: defines how the training data will be saved\n",
    " - `s3_data`: the location of the s3 data to train\n",
    " - `distribution`: default is fullyreplicated\n",
    " - `content_type`: MIME type of the input data, default is none\n",
    " - `s3_data_type=S3Prefix` all objects with this prefix will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n",
      "Wall time: 19.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data = sagemaker.inputs.TrainingInput(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.inputs.TrainingInput(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"objective3\" style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "    <center><h1><strong>Demonstrate how to train the machine learning model.</strong></h1></center>\n",
    "    <ul>\n",
    "        <li>Overview:\n",
    "            <ol>\n",
    "                <li>Step 1: Set up containers (which are servers that runs the model)</li>\n",
    "                <li>Step 2: Set up model hyperparameters</li>\n",
    "                <li>Step 3: Fit the model</li>\n",
    "            </ol>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1: Set up Containers</h3>\n",
    "\n",
    " - Set the location of the model in your S3 directory: `s3_output_location = f's3://{data_bucket}/{subfolder}/output/'`\n",
    " - Name the training session: `sess = sagemaker.Sessions()`\n",
    " - Set up the container: `container = sagemaker.amazon.amazon_estimator.image_uris.retrieve()`\n",
    " - `\"blazingtext\"`: the framework to use in the container\n",
    " - `boto3.Session().region_name`: the AWS region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2: Set up the model hyperparameters</h3>\n",
    "\n",
    " - Part 1 <strong>Set up the Estimator</strong>: `estimator = sagemaker.estimator.Estimator(...)`\n",
    " - `container`: to configure the server\n",
    " - `role`: to assign the role set up at the beginning of project `role = sagemaker.get_execution_role()`\n",
    " - `instance_count`: sets up the number of servers used to train the model\n",
    " - ` instance_type='m1.c4.4xlarge'`: sets up the size of the server\n",
    " - `max_run = 600`: maximum number of minutes the server will run before it shuts down\n",
    " - `output_path=s3_output_location`: where to save the data `s3_output_location = f's3://{data_bucket}/{subfolder}/output/'\n",
    " - `sagemaker_session=sess`: This names the training session<br>\n",
    " <br>\n",
    " - Part 2 <strong>Specific Hyperparameters</strong>:\n",
    " - `mode = \"supervised\"`: specifies the mode that will be used by BlazingText\n",
    " - `epochs = 10`: sets the number of epochs that will be used in the training. The number of times that BlazingText performs over the entire dataset.\n",
    " - `vector_dim = 10`: sets the number of vectors\n",
    " - `early_stopping = True`: enables early stopping, a technique used to select the best model\n",
    " - `patience = 4`: specifies when to stop early, so there after 4 epochs if model doesn't improve\n",
    " - `min_epochs = 5`: sets the minimal number of ephocs even if there is no improvement after the 1st one \n",
    " - `word_ngrams=2`: sets the number of ngrams to use, in this case, a bigram <br>\n",
    " <br>\n",
    " - Part 3 <strong>Fit the model</strong>:\n",
    " - `estimator.fit({'train': train_data, 'validation': validation_data})`: use the fit() method, which takes a dictionary that has the training data and the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-05 02:31:39 Starting - Starting the training job...\n",
      "2021-03-05 02:32:03 Starting - Launching requested ML instancesProfilerReport-1614911498: InProgress\n",
      "......\n",
      "2021-03-05 02:33:05 Starting - Preparing the instances for training.........\n",
      "2021-03-05 02:34:32 Downloading - Downloading input data\n",
      "2021-03-05 02:34:32 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[03/05/2021 02:34:33 WARNING 140688403318144] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/05/2021 02:34:33 WARNING 140688403318144] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/05/2021 02:34:33 INFO 140688403318144] nvidia-smi took: 0.025337696075439453 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[03/05/2021 02:34:33 INFO 140688403318144] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[03/05/2021 02:34:33 INFO 140688403318144] Processing /opt/ml/input/data/train/train.csv . File size: 39.061180114746094 MB\u001b[0m\n",
      "\u001b[34m[03/05/2021 02:34:33 INFO 140688403318144] Processing /opt/ml/input/data/validation/validation.csv . File size: 9.768644332885742 MB\u001b[0m\n",
      "\u001b[34mRead 7M words\u001b[0m\n",
      "\u001b[34mNumber of words:  23035\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/validation.csv\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0282  Progress: 43.61%  Million Words/sec: 42.14 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0253  Progress: 49.49%  Million Words/sec: 42.34 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0223  Progress: 55.41%  Million Words/sec: 42.52 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.912604\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0187  Progress: 62.64%  Million Words/sec: 37.54 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.913483\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0149  Progress: 70.30%  Million Words/sec: 34.40 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.914112\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0113  Progress: 77.37%  Million Words/sec: 32.07 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0084  Progress: 83.24%  Million Words/sec: 32.69 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.912015\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0032  Progress: 93.65%  Million Words/sec: 31.41 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.91491\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: -0.0000  Progress: 100.00%  Million Words/sec: 29.65 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.9149\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 29.32 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 29.32\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 2.56\n",
      "\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.9904\u001b[0m\n",
      "\u001b[34mNumber of train examples: 400656\n",
      "\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.9149\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 100165\u001b[0m\n",
      "\n",
      "2021-03-05 02:35:06 Uploading - Uploading generated training model\n",
      "2021-03-05 02:35:06 Completed - Training job completed\n",
      "Training seconds: 55\n",
      "Billable seconds: 55\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = f's3://{data_bucket}/{subfolder}/output'\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "container = sagemaker.amazon.amazon_estimator.image_uris.retrieve(\"blazingtext\", boto3.Session().region_name)\n",
    "#container = sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, \"blazingtext\", \"latest\")\n",
    "\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(container,\n",
    "                                         role,\n",
    "                                         instance_count=1, \n",
    "                                         instance_type='ml.c4.4xlarge',\n",
    "                                         max_run = 600,\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess,\n",
    "                                         content_type = 'text/plain')\n",
    "\n",
    "estimator.set_hyperparameters(mode=\"supervised\",\n",
    "                            epochs=10,\n",
    "                            vector_dim=10,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=2)\n",
    "\n",
    "estimator.fit({'train': train_data, 'validation': validation_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "    <center><h1><strong>Evaluate Model Performance.</strong></h1></center>\n",
    "    <ul>\n",
    "        <li>The training rounds output provides information on how the algorithm is progressing.</li><br>\n",
    "        <li>The most important information is the training and validation score notifications</li><br>\n",
    "        <li>The training accuracy of this model is over 95%.</li><br>\n",
    "        <li>The validation accuracy of this model is 90%.</li><br>\n",
    "        <li>Both are over 90% which indicates a good model that also generalizes well.</li><br>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"objective5\" style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "    <center><h1><strong>Demonstrate how to host and test the model over the cloud.</strong></h1></center>\n",
    "    <ul>\n",
    "        <li>This step will set up a server to receive data and returns a decision.</li><br>\n",
    "        <li>Overview:\n",
    "            <ol>\n",
    "                <li>Step 1: Prepare endpoint.</li>\n",
    "                <li>Step 2: Deploy endpoint.</li>\n",
    "                <li>Step 3: Test the model.</li>\n",
    "                <li>Step 4: As needed, delete endpoint.</li>\n",
    "            </ol>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1: Prepare Endpoint</h3>\n",
    "\n",
    " - `endpoint_name= 'customer-support-slugify`: Label endpoint so that you do not create duplicate endpoints.\n",
    " - `try: delete endpoint if it exist, except: if not exist do nothing`: used here to check if endpoint exist, if it exist, delete, if not, keep going.\n",
    " - `sess.delete_endpoint(..)`: will delete existing endpoint if it exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'customer-support-slugify'\n",
    "\n",
    "try:\n",
    "    sess.delete_endpoint(sagemaker.predictor.Predictor(endpoint=endpoint_name, content_type = 'text/plain').endpoint)\n",
    "    print('Warning: Existing endpoint deleted to make way for your new endpoint.')\n",
    "    sleep(30)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2: Deploy Endpoint</h3>\n",
    "\n",
    " - `estimator.deploy()`: Deploy a candidate to a SageMaker Inference Pipeline.\n",
    " - `initial_instance_count`: the initial number of instances to run in the endpoint created from the model\n",
    " - `instance_type`: the EC2 instance type to deploy this model\n",
    " - `endpoint_name`: the name of the endpoint to create, by default none, and a unique endpoint name will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "text_classifier = estimator.deploy(initial_instance_count = 1,\n",
    "                                instance_type = 'ml.t2.medium',\n",
    "                                endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3: Testing the Model</h3>\n",
    "\n",
    " - A prediction is made from a sample tweet.\n",
    " - `tweet = \"I am so upset I need help\"`: test tweet\n",
    " - `tokenized_tweet = [''.join(nltk.word_tokenize(tweet))]`: This takes the tweet, tokenizes it using nltk, and then joins it in a string.\n",
    " - `payload = {\"instance\" : tokenized_tweet}`: Converts data into a dictionary, the key `instance` and the value the tokenized tweet.\n",
    " - `response = text_classifier.predict(json.dumps(payload))`: This code converts the payload dictionary into a json string, and then passes that into our machine learning model to predict whether this should be escalated to a human customer service or an automated machine.\n",
    " - `escalate = pd.read_json(response)`: this code will convert the response into a pandas dataframe\n",
    " - `escalte`: will print out the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"I am very happy to be finished the chapter\"\n",
    "tweet = \"I was frustrated by my competing priorities\"\n",
    "\n",
    "tokenized_tweet = [slugify(tweet, separator=' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': ['__label__1'], 'prob': [0.9995021820068359]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {\"instances\" : tokenized_tweet}\n",
    "response = text_classifier.predict(json.dumps(payload), initial_args={'ContentType': 'application/json'})\n",
    "escalate = json.loads(response.decode(\"utf-8\"))\n",
    "escalate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the Endpoint (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment out this cell to remove the endpoint if you want the endpoint to exist after \"run all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Endpoint (optional)\n",
    "# Comment out this cell to remove the endpoint if you want the endpoint to exist after \"run all\"\n",
    "\n",
    "#sess.delete_endpoint(text_classifier.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"objective6\" style=\"font-size:16px; border:1px solid black; padding:10px\">\n",
    "    <center><h1><strong>Demonstrate how to set up serverless API endpoint.</strong></h1></center>\n",
    "     <ul style=\"list-style-type:none;\"><h4><strong>AWS Chalice</strong></h4>\n",
    "        <li>\n",
    "            <ol>\n",
    "                <li>Project Setup</li>\n",
    "                <li>Create New Chalice Project</li>\n",
    "                <li>Set up Configuration Files</li>\n",
    "                <li>Set up code that serves SageMaker endpoint</li>\n",
    "                <li>Set up Requirements File</li>                \n",
    "                <li>Deploy Chalice project</li>\n",
    "                <li>Sever Predictions</li>                \n",
    "            </ol>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 3px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1: Project Setup</h2>\n",
    "\n",
    "<ol>\n",
    "    <li>Set up environment on local machine (via terminal or powershell)</li>\n",
    "    <li>Activate virtual environment</li>\n",
    "    <li>Install boto3</li>\n",
    "    <li>Install <strong><code><a href=\"https://pypi.org/project/awscli/\">awscli</a></strong></code>: is a package that provides a unified command line interface for Amazon Web Services.  Some users are on mac, others on pc. This package lets anyone interact with AWS from their terminal, powershell, etc. See documentation for details.</li>\n",
    "    <li>Install <strong><code><a href=\"https://chalice.readthedocs.io/en/stable/\">chalice</a></strong></code>: is a package that allows users to quickly create and deploy applications that use Amazon API Gateway and AWS Lambda.</li>\n",
    "    <li>Set up AWS credentials on your local computer\n",
    "        <ol type=\"a\">\n",
    "            <li>Setting up your AWS credentials on your AWS account</li>\n",
    "            <li>Create and download AWS credential</li>\n",
    "            <li>Configure your AWS credential on your local computer</li>            \n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 1.1 - 1.5:<br>Set up environment on local machine, activate environment, install modules.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">Shell</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "  <li>&#x24; python3.6 -m venv env</li>\n",
    "  <li>&#x24; source env/bin/activate</li>\n",
    "  <li>(env)&#x24; pip install boto3</li>\n",
    "  <li>(env)&#x24; pip install awscli</li>\n",
    "  <li>(env)&#x24; pip install chalice</li>\n",
    "</ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 1.6A: Setting up your AWS credentials on your AWS account.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html\">AWS security</a> can be accessed through account \"My security credentials\" tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 1.6B: Create and download AWS credential.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Your security credentials dashboard, go to \"Access keys (access key ID and secret access key)\"\n",
    " - They layout is subject to change\n",
    " - When you click on the tab, a \"create new access key\" button is available\n",
    " - Click on that button and you will be able to download a <code>csv</code> file with your information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 1.6C: Configure your AWS credential on your local computer.</h3>\n",
    "\n",
    " - You will use the keys you created and downloaded in this step\n",
    " - You will also need the region your SageMaker AWS server is located. This can be located on your console url.\n",
    " - You do not have to enter anything in the `output format [none]` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">Shell</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "  <li>(env)&#x24; aws configure</li>\n",
    "  <li>aws_access_key_id=&#60;your-access-key-id&#62;</li>\n",
    "  <li>aws_secret_access_key=&#60;your-secret-access-key&#62;</li>\n",
    "  <li>region=&#60;your-region&#62;</li>    \n",
    "  <li>output format [None]= leave empty</li> \n",
    "</ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 3px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Create New Project</h2>\n",
    "\n",
    "<ol>\n",
    "    <li>Create new project from shell using <code>chalice new-project &#60;project name&#62;</code></li>\n",
    "    <li>Get familiar with project directory.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 2.1: Create New Project</h3>\n",
    "From shell using <code>chalice new-project &#60;project name&#62;</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">Shell</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "  <li>(env)&#x24; chalice new-project tweet_escalator</li>\n",
    "</ul>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 2.2: Get familiar with project directory</h3>\n",
    "<ul>\n",
    "    <li>Running <code>chalice new-project</code> will create a project folder that contains several folders and files needed to run your program over the web.</li>\n",
    "    <li>It's important to be familiar with the project directory and the files it contains, as you will need to make know how to make modifications to ensure your program runs as intended.</li>\n",
    "    <li><strong><font color=\"red\">You will need to have a code editor for all subsequent steps</font></strong>.</li>\n",
    "    <li>The free code editor <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a> was used in this project.</li>\n",
    "</ul>\n",
    "<hr>\n",
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">Directory</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "    <li>&#60;project-name&#62;</li>\n",
    "    <li>|</li>\n",
    "    <li>&#x22A2;.chalice/&#x231e;config.json, policy-dev.json</li>\n",
    "    <li>|</li>\n",
    "    <li>|</li>\n",
    "    <li>&#8866;.gitignore</li>\n",
    "    <li>&#8866;app.py</li>\n",
    "    <li>&#x231e;requirements.txt</li>\n",
    "</ul>  \n",
    "</div>\n",
    "<hr>\n",
    "<ul>There are three major files and subfolders:\n",
    "    <li><strong><code>app.py</code></strong>: contains the Python code that will run when the endpoint is accessed.</li>\n",
    "    <li><strong><code>.chalice</code></strong>: contains all the configuration files. \n",
    "        <ol>We will need two files in this directory:\n",
    "            <li><code><a href=\"https://chalice.readthedocs.io/en/stable/topics/configfile.html\"?>config.json</a></code>: file is used to control what happens when you deploy your chalice project. This is automatically created for you, but you need to configure this file and understand how to do so, otherwise your project will not deploy. This file will tell Chalice what to do when the project is deployed.</li>\n",
    "            <li><code>policy-dev.json</code>: this is a file we will create and add to this directory. This code will sets the permissions that will allow the Lambda function to call the SageMaker endpoint. This code will tell chalice how to run the program once it is deployed.</li>\n",
    "        </ol>\n",
    "    </li><br>\n",
    "    <li><strong><code>requirements.txt</code></strong>: contains a list of Python libraries that the application will need to run. This is also essential.</li>\n",
    "</ul>\n",
    "</ul>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ACE5F4; text-indent: 1.5em;\">Part 3. Set up Configuration Files</h2>\n",
    "\n",
    " - Chalice API needs to have access to your AWS Lambda Function\n",
    " - This step will ensure to give the AWS Lambda Function permission to access your SageMaker Endpoint\n",
    " - You will need to update the default `confing.json` file that was provided\n",
    " - Faling to do this will result in errors when you serve your predictions over the web\n",
    " - Below is a reminder of what subdirectory of your project folder that we will be working on\n",
    " - Use your code editor to carry out the following steps\n",
    " \n",
    " <br>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "    <li>&#60;project-name&#62;</li>\n",
    "    <li>|</li>\n",
    "    <li><mark><font color=\"red\">&#x22A2;.chalice/&#x231e;config.json, policy-dev.json</font></mark></li>\n",
    "    <li>|</li>\n",
    "    <li>|</li>\n",
    "    <li>&#8866;.gitignore</li>\n",
    "    <li>&#8866;app.py</li>\n",
    "    <li>&#x231e;requirements.txt</li>\n",
    "</ul>  \n",
    "</div>\n",
    "<ol>Steps:\n",
    "    <li>Modify <code>config.json</code> file.</li>\n",
    "    <li>Create <code>policy-dev.json</code> file.</li>  \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 3.1: Modify <code>config.json</code> file</h3>\n",
    "\n",
    " - The <a href=\"https://chalice.readthedocs.io/en/stable/topics/configfile.html\">configure file</a> is created when a new project is created using `chalice new-project` \n",
    " - This file is staved in the `.chalice` directory\n",
    " - This file lets you control what happens when you deploy chalice\n",
    " - <a href=\"https://chalice.readthedocs.io/en/stable/topics/stages.html\">Stage configurations</a> lets you configure what should happens accross all the stages of your application\n",
    " - The stage configuration is automatically provided when you created a new project, but it needs to be updated.\n",
    " - This file will utilize Lambda Specific Configuration \n",
    " \n",
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">config.json</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "    <ul style=\"list-style-type:none;\">\n",
    "    <li>{</li>\n",
    "    <li style=\"text-indent: 1em;\">\"version\": \"2.0\",</li>\n",
    "    <li style=\"text-indent: 1em;\">\"app_name\": \"tweet_escalator\",</li>\n",
    "    <li style=\"text-indent: 1em;\">\"stages\": {</li>\n",
    "    <li style=\"text-indent: 1.5em;\">\"dev\": {</li>\n",
    "    <li style=\"text-indent: 3em;\">\"autogen_policy\": false,</li>\n",
    "    <li style=\"text-indent: 3em;\">\"api_gateway_stage\": \"api\",</li>\n",
    "    <li style=\"text-indent: 3em;\">\"iam_policy_file\" : \"policy-dev.json\"</li>           \n",
    "    <li style=\"text-indent: 1.5em;\">}</li>\n",
    "    <li style=\"text-indent: 1em;\">}</li>\n",
    "    <li>}</li>        \n",
    "    </ul>\n",
    "</div>\n",
    "<hr>\n",
    "<h3>Lambda Specific Configurations</h3>\n",
    "\n",
    " - Are a set of configuration values that can be specified for each Lambda Function\n",
    " - Each stage in a Lambda function can have many Lambda specific configurations\n",
    " - You specify these functions in your configuration file(s)\n",
    " - They are added as a dictionary `\"key\"` : `\"value\"`\n",
    "\n",
    "<ul><strong>Some of the Available functions:</strong>\n",
    "    <li>autogen_policy</li>\n",
    "    <li>environment_variables</li>\n",
    "    <li>iam_policy_file</li>\n",
    "    <li>iam_role_arn</li>\n",
    "    <li>manage_iam_role</li>    \n",
    "</ul>\n",
    "<hr>\n",
    "<ul><strong>Code Explained</strong>\n",
    "    <li><strong><code><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-versions.html\">\"version\"</a></code></strong>: is a lambda specific configuration that is used to specify the particular code that will be used.</li>\n",
    "    <li><strong><code>\"app_name\"</code></strong>: here you will specific the name of your chalice project</li>\n",
    "    <li><strong><code>\"stages\"</code></strong>: this is the default stage added to your file, here we will add specific configuration values:\n",
    "    <ul>\n",
    "        <li><strong><code>\"dev\"</code></strong>: is for developmennt. We only have one sage in this example. Some programs will have many more stages.  This stage has additional configurations\n",
    "            <ul>\n",
    "        <li><strong><code>\"autogen_policy\"</code></strong>: is boolean value that indicates if chalice should try to automatically generate an IAM policy based on analyzing your application source code. The default value is true. <strong><font color=\"red\">You must set this to false!</font></strong>.  We want to tell chalice how to reach our SageMaker endpoint, and that it should specifically use a new file we will create that has this information. Your program will not work with this specified.</li>\n",
    "        <li><strong><code>\"api_gateway_stage\"</code></strong>: The name of the API gateway stage. This will also be the URL prefix for your API (https://endpoint/prefix/your-api).</li>\n",
    "        <li><strong><code>\"iam_policy_file\"</code></strong>: When <code>autogen_policy</code> is false, chalice will try to load an IAM policy from disk instead of auto-generating one based on source code analysis. The default location of this file is .chalice/policy-stage-name.json, for us, we will use <code>policy-dev.json</code>. You can change the filename by providing this iam_policy_file config option. This filename is relative to the .chalice directory.</li>        \n",
    "            </ul>\n",
    "       </li>\n",
    "    </ul>\n",
    "    </li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: #ACE5F4;\">Step 3.2: Create <code>policy-dev.json</code> file</h3>\n",
    "\n",
    " - This file will set permissions for the Lambda Function to Access AWS Sagemaker\n",
    " - An error will occur without this code\n",
    " \n",
    " <ul><strong>Code Explained</strong>\n",
    "    <li><strong><code><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_version.html\">\"version\"</a></code></strong>: \n",
    "        <ul>\n",
    "        <li>This IS Version JSON policy element and is different from a policy version.</li> \n",
    "        <li>The Version policy element is used within a policy and defines the version of the policy language.</li>\n",
    "        <li>A policy version, on the other hand, is created when you make changes to a customer managed policy in IAM. This is what we have in the policy.json file.</li> \n",
    "        <li>The Version policy element specifies the language syntax rules that are to be used to process a policy. </li>\n",
    "        <li>To use all of the available policy features, include the following Version element before the Statement element in all of your policies.</li>\n",
    "           <li> This is the current version of the policy language, and you should always include a Version element and set it to 2012-10-17.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong><code><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_statement.html\">\"Statement\"</a></code></strong>: \n",
    "        <ul>\n",
    "            <li>is a required main element of a policy.</li>\n",
    "            <li>The <code>statement</code> element can consist of a single statement or an array of individual statements</li>\n",
    "            <li>Individual statements are enclosed with curly braces <code>{ }</code>.</li>\n",
    "            <li>An array of statements are enclosed in brackets <code>[ ]</code>.<li>\n",
    "            <li>This project uses two statements, the first once will save information on each prediction, and the second statement will invoke the SageMaker endpoint.<li>\n",
    "        </ul>\n",
    "<li><strong><code><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_sid.html\">\"Sid\"</a></code></strong>: \n",
    "    <ul>\n",
    "    <li>The Sid (statement ID) is an optional identifier that you provide for the policy statement.</li>\n",
    "        <li>You can assign a Sid value to each statement in a statement array. </li>\n",
    "        <li>In services that let you specify an ID element, such as SQS and SNS, the Sid value is just a sub-ID of the policy document's ID.</li>\n",
    "        <li>In IAM, the Sid value must be unique within a JSON policy.</li> \n",
    "        <li>In the code below, we have two Sid, the first one identifies the statement to save information on each run, and the second to identify the code that will invoke our SageMaker endpoint</li>\n",
    "    </ul>\n",
    "<li><strong><code><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_action.html\">\"Action\"</a></code></strong>: \n",
    "    <ul>\n",
    "    <li>The Action element describes the specific action or actions that will be allowed or denied.</li>\n",
    "        <li>Statements must include either an <code>Action</code> or <code>NotAction element</code>.</li>\n",
    "        <li>AWS service has its own set of actions that describe tasks that you can perform with that service.</li>\n",
    "        <li>SageMakers action, resources and conditions keys can be found <a href=\"https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonsagemaker.html\">here</a>.</li> \n",
    "        <li>You specify a value using a service namespace as an action prefix (iam, ec2, sqs, sns, s3, etc.) followed by the name of the action to allow or deny. Multiple values for the Action element are described using the <code>\"Action\" : [Action elements array]</code></li>\n",
    "        <li>The action key and values can be found in the documentation provided by AWS.</li>\n",
    "        <li>The actions for <code>\"Sid\": \"VisualEditor0\"</code> instruct Lambda to save all information into the resources statement.</li>\n",
    "        <li>The actions for <code>\"Sid\": \"VisualEditor1\"</code> instruct Lambda to invoke the SageMaker endpoint that is described in resources statement.</li>        \n",
    "    </ul>\n",
    "<li><strong><code><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_action.html\">\"Action\"</a></code></strong>: \n",
    "    <ul>\n",
    "    <li>The Action element describes the specific action or actions that will be allowed or denied.</li>\n",
    "        <li>Statements must include either an <code>Action</code> or <code>NotAction element</code>.</li>\n",
    "        <li>AWS service has its own set of actions that describe tasks that you can perform with that service.</li>\n",
    "        <li>SageMakers action, resources and conditions keys can be found <a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_resource.html\">Resource</a>.</li> \n",
    "        <li>The Resource element specifies the object or objects that the statement covers.</li>\n",
    "        <li>Statements must include either a Resource or a NotResource element.</li>\n",
    "        <li>You specify a resource using an Amazon Resource Name (ARN).</li>\n",
    "        <li>Information on the formats for the ARN can be found in the <a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html#identifiers-arns\">AIM ARNs</a></li>\n",
    "        <li>Each service has its own set of resources, we can find our ARN from the endpoint we created in our code after we developed our model.</li>\n",
    "        <li>For <code>\"Sid\": \"VisualEditor0\"</code>, we used <code>\"Resource\": \"arn:aws:logs:*:*:*\"</code> which  instructs Labmda to use our endpoint, go to the logs section, and save all three actions (create log stream, put log events, and create a log group).</li>\n",
    "        <li>For <code>\"Sid\": \"VisualEditor1\"</code>, we used a wildcard <code>\"Resource\": \"*\"</code>. This is because some services do not let you specify actions for individual resources; instead, any actions that you list in the Action or NotAction element apply to all resources in that service. In these cases, you use the wildcard * in the Resource element.</li>\n",
    "    </ul>     \n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">policy-dev.json</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "    <ul style=\"list-style-type:none;\">\n",
    "<li>{</li>\n",
    "    <li style=\"text-indent: 1em;\">\"Version\": \"2012-10-17\",</li>\n",
    "    <li style=\"text-indent: 1em;\">\"Statement\": [</li>\n",
    "        <li style=\"text-indent: 1.5em;\">{</li>\n",
    "            <li style=\"text-indent: 3em;\">\"Sid\": \"VisualEditor0\",</li>\n",
    "           <li style=\"text-indent: 3em;\"> \"Effect\": \"Allow\",</li>\n",
    "            <li style=\"text-indent: 3em;\">\"Action\": [</li>\n",
    "                <li style=\"text-indent: 4em;\">\"logs:CreateLogStream\",</li>\n",
    "                <li style=\"text-indent: 4em;\">\"logs:PutLogEvents\",</li>\n",
    "                <li style=\"text-indent: 4em;\">\"logs:CreateLogGroup\"</li>\n",
    "            <li style=\"text-indent: 3em;\">],</li>\n",
    "            <li style=\"text-indent: 3em;\">\"Resource\": \"arn:aws:logs:*:*:*\"</li>\n",
    "        <li style=\"text-indent: 1.5em;\">},</li>\n",
    "        <li style=\"text-indent: 1em;\">{</li>\n",
    "            <li style=\"text-indent: 2em;\">\"Sid\": \"VisualEditor1\",</li>\n",
    "            <li style=\"text-indent: 2.5em;\">\"Effect\": \"Allow\",</li>\n",
    "            <li style=\"text-indent: 2.5em;\">\"Action\": \"sagemaker:InvokeEndpoint\",</li>\n",
    "            <li style=\"text-indent: 2.5em;\">\"Resource\": \"*\"</li>\n",
    "       <li style=\"text-indent: 2em;\"> }</li>\n",
    "    <li style=\"text-indent: 1.5em;\">]</li>\n",
    "}<br>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ACE5F4; text-indent: 1.5em;\">Part 4. Set up code that serves SageMaker endpoint</h2>\n",
    "\n",
    " - In this step, we will update our app.py file so that it will serve all the python code in our SageMaker endpoint.\n",
    " \n",
    " <br>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "    <li>&#60;project-name&#62;</li>\n",
    "    <li>|</li>\n",
    "    <li>&#x22A2;.chalice/&#x231e;config.json, policy-dev.json</li>\n",
    "    <li>|</li>\n",
    "    <li>|</li>\n",
    "    <li>&#8866;.gitignore</li>\n",
    "    <li><mark><font color=\"red\">&#8866;app.py</font></mark></li>\n",
    "    <li>&#x231e;requirements.txt</li>\n",
    "</ul>  \n",
    "</div>\n",
    "<hr>\n",
    "<ul>Content:\n",
    "    <li>Modify <code>app.py</code> file.</li>\n",
    "    <li>Code explained.</li>  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chalice import Chalice\n",
    "import json\n",
    "import boto3\n",
    "from slugify import slugify\n",
    "\n",
    "app = Chalice(app_name='tweet_escalator')\n",
    "\n",
    "@app.route('/') # this is just the default route, you can use this to make sure your code is setup\n",
    "def index():\n",
    "    return 'Hello world!'\n",
    "\n",
    "\n",
    "@app.route('/tweet/{tweet}')\n",
    "def return_tweet(tweet):\n",
    "    tokenized_tweet = [slugify(tweet, separator=' ')]\n",
    "    payload = json.dumps({\"instances\" : tokenized_tweet})\n",
    "\n",
    "    endpoint_name = 'customer-support-slugify'\n",
    "\n",
    "    runtime = boto3.Session().client(service_name='sagemaker-runtime', region_name='us-west-1')\n",
    "\n",
    "    response = runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=payload)\n",
    "\n",
    "    response_list = json.loads(response['Body'].read().decode())\n",
    "    response = response_list[0]\n",
    "\n",
    "    if '1' in response['label'][0]:\n",
    "        escalate = 'Yes'\n",
    "    else:\n",
    "        escalate = 'No'\n",
    "\n",
    "    full_response = {\n",
    "        'Tweet': tweet,\n",
    "        'Tokenised tweet': tokenized_tweet,\n",
    "        'Escalate': escalate,\n",
    "        'Confidence': response['prob'][0]\n",
    "    }\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ACE5F4; text-indent: 1.5em;\">app.py code explained</h2>\n",
    "\n",
    " - <strong><code>@app.route('/tweet/{tweet}')</code></strong>: @app.route('/tweet/{tweet}')\n",
    " - <strong><code>def return_tweet(tweet):</code></strong>: sets-up the function and takes in the tweet as a parameter\n",
    " - <strong><code>tokenized_tweet = [slugify(tweet, separator=' ')]</code></strong>: uses slugify to transform the text into an array of tokens.\n",
    " - <strong><code>payload = json.dumps({\"instances\" : tokenized_tweet})</code></strong>: converts the tokenized text into a json format. This will be needed as the input for our model.\n",
    " - <strong><code>endpoint_name = 'customer-support-slugify'</code></strong>: This is the endpoint name that we gave it in our code. We need to include it here as it has to be invoked at each run.\n",
    " - <strong><code>runtime = boto3.Session().client(service_name='sagemaker-runtime', region_name='us-west-1')</code></strong>: this code prepares our endpoint that will be used by our configuration files\n",
    " - <strong><code>response = runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=payload)</code></strong>: This code invokes the endpoint, provides it our test data, and gets the response, aka our prediction with associated values.\n",
    " - <strong><code>response_list = json.loads(response['Body'].read().decode())</code></strong>: this code converts the response data into a list. We are transforming it here for our display needs.\n",
    " - <strong><code>response = response_list[0]</code></strong>: We only need the first part of the list, the rest is information we don't want. The first item has our prediction.\n",
    " - <strong><code>if ... else statement</code></strong>: This will set the decision and this will be returned to the client\n",
    " - <strong><code>full_response {...}</code></strong>: This will save all our parameters and data into a dictionary that we will return to the client. We are serving them the prediction back.\n",
    " - <strong><code>return full_response</code></strong>: Returns the full response dictionary\n",
    " - We could pass the full response to some other application. In this example, the data will be displayed on the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ACE5F4; text-indent: 1.5em;\">Part 5. Set up Requirements File</h2>\n",
    "\n",
    " - In this step, we will update our requirements.txt file, which is a file that lists any Python libraries that your application needs to \n",
    " \n",
    " <br>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "    <li>&#60;project-name&#62;</li>\n",
    "    <li>|</li>\n",
    "    <li>&#x22A2;.chalice/&#x231e;config.json, policy-dev.json</li>\n",
    "    <li>|</li>\n",
    "    <li>|</li>\n",
    "    <li>&#8866;.gitignore</li>\n",
    "    <li>&#8866;app.py</li>\n",
    "    <li><mark><font color=\"red\">&#x231e;requirements.txt</font></mark></li>\n",
    "</ul>  \n",
    "</div>\n",
    "<hr>\n",
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">requirements.txt</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "    <ul style=\"list-style-type:none;\">\n",
    "    <li>python-slugify</li>   \n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2 style=\"background-color: #ACE5F4; text-indent: 1.5em;\">Part 6. Deploy Chalice project</h2>\n",
    "\n",
    " - In this step, we will update our requirements.txt file, which is a file that lists any Python libraries that your application needs to \n",
    " - This regenerates your Lambda function on AWS with a few additions\n",
    " - The Lambda function now has permission to invoke the SageMaker endpoint.\n",
    " - The Lambda function has installed the slugify library so it can be used by the function.\n",
    " \n",
    " <br>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "<ul style=\"list-style-type:none;\">\n",
    "    <li><font color=\"red\">&#60;tweet_escalator&#62;</font></li>\n",
    "    <li>|</li>\n",
    "    <li>&#x22A2;.chalice/&#x231e;config.json, policy-dev.json</li>\n",
    "    <li>|</li>\n",
    "    <li>|</li>\n",
    "    <li>&#8866;.gitignore</li>\n",
    "    <li>&#8866;app.py</li>\n",
    "    <li>&#x231e;requirements.txt</li>\n",
    "</ul>  \n",
    "</div>\n",
    "<hr>\n",
    "<h3 style=\"background-color: lightyellow; text-indent: 1.5em;\">shell > tweet_escalator folder</h3>\n",
    "<div style=\"background-color: #F0F0F0;\">\n",
    "    <ul style=\"list-style-type:none;\">\n",
    "    <li>(env)&#x24; chalice deploy</li>   \n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ACE5F4; text-indent: 1.5em;\">Part 7. Sever Predictions</h2>\n",
    "\n",
    " - This step requires that you use the rest API in your shell\n",
    " - click the Rest API URL link that is shown in your terminal window after you run \n",
    " - then type in `tweet/{tweet}` at the end of your rest API\n",
    " - substitute text with words seperated with a `-` where the `{tweet}` in located, remove the curly brackets\n",
    " - hit enter\n",
    " - the response will be displayed on the screen\n",
    " - Example: `{\"Tweet\":\"I-am-very-angry\",\"Tokenized tweet\":[\"i am very angry\"], \"Escalate\":\"Yes\",\"Confidence\":1.0000098943710327}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
