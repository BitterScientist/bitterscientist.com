{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation Libraries: Standard dataframes and array libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 #for querying data \n",
    "\n",
    "# Data Visualization Libraries:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Analysis: Statistics and Machine Learning Libraries\n",
    "from scipy import stats\n",
    "import scikit_posthocs as sp\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Displaying plots in jupter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Jupyter Notebook Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns (pandas will collapse some columns if we don't set this option)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Prepare for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step a: Import data using .read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .read_csv() method\n",
    "# We use individual file imports rather than the whole databse because the database is a very large file\n",
    "# This is a subset\n",
    "bregman = pd.read_csv('static/documents/bregman')\n",
    "rendon = pd.read_csv('static/documents/rendon')\n",
    "soto = pd.read_csv('static/documents/soto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step b: Use .concat() method to combine player dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of databases\n",
    "team = [bregman, rendon, soto]\n",
    "# Use the .concat() method and pass the list of dataframes\n",
    "result = pd.concat(team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step c: Replace Batter ID's with Player Last Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "result['batter'].replace({608324: 'Bregman', 543685: 'Rendon', 665742: 'Soto'}, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step d: Delete rows in the 'events' table with missing values\n",
    " - we are only interested in batter events and must omit rows that lack this key feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .dropna() method to omit any rows where the column 'events' has a missing value\n",
    "results = result.dropna(how='any', subset=['events'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step e: Inspect data by using the .pivot_table() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the .pivot_table() method to display a summary table\n",
    "# The batter names are used as the index\n",
    "pivot = results.pivot_table(index=\"batter\", columns='events', aggfunc='size', fill_value=0)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Entire Season and World Series Home Run Total by player\n",
    " - Use individual dataframes\n",
    " - Use matplotlib .bar() as a data vis option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to plot\n",
    "# replace batter id with name\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Store player names in array 'x'\n",
    "# Store homerun values in array home_run\n",
    "x = pivot.home_run.index.values\n",
    "home_runs = pivot.home_run.values\n",
    "\n",
    "# Use a list comprehension to create a list of playe positions\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "# Create plot and labels\n",
    "plt.bar(x_pos, home_runs, color='blue', alpha = 0.7)\n",
    "plt.xlabel(\"Players\")\n",
    "plt.ylabel(\"Home Runs\")\n",
    "plt.title(\"Total Home Runs (Including World Series)\")\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "plt.savefig(\"static/images/total_home_runs.png\", bbox_inches='tight') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soto made more Home Runs than Rendon, when counting playoffs and world series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1: Evaluate Player Batting Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order = result.events.value_counts().index\n",
    "\n",
    "sns.set(rc={'figure.figsize':(25,15)})\n",
    "sns.set(font_scale=1.5)\n",
    "result_events = sns.countplot(x='events', hue = \"batter\", data=result, order=order)\n",
    "result_events.set_xticklabels(result_events.get_xticklabels(), rotation=45)\n",
    "fig = result_events.get_figure()\n",
    "fig.savefig(\"static/images/batter_event_bar_plots.png\", bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of batted events per player\n",
    "results.groupby('batter')['events'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home run rate\n",
    "print(f'Bregman HR rate {45/765 * 100}, Rendon HR Rate {37/711* 100}, Soto HR Rate {39/730* 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 2: Determine which player had the highest hit distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 2 Step 1: Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearn up data by removing an NaN\n",
    "# Use the .dropna() method to omit any rows where the column 'events' has a missing value\n",
    "results_hd = results.dropna(how='any', subset=['hit_distance_sc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by player and only for home run events\n",
    "bregman_hd = results_hd[(results_hd[\"batter\"] == \"Bregman\") & (results_hd[\"events\"] == \"home_run\")]\n",
    "rendon_hd = results_hd[(results_hd[\"batter\"] == \"Rendon\") & (results_hd[\"events\"] == \"home_run\")]\n",
    "soto_hd = results_hd[(results_hd[\"batter\"] == \"Soto\") & (results_hd[\"events\"] == \"home_run\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine filtered data\n",
    "frames = [bregman_hd, rendon_hd, soto_hd]\n",
    "filterd_hd = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 2 Step 2: Aggregate Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bregman_hd_metrics = bregman_hd[[\"hit_distance_sc\"]].describe()\n",
    "bregman_hd_metrics = bregman_hd_metrics.rename(columns={\"hit_distance_sc\" : \"Bregman Hit Distance\"})\n",
    "rendon_hd_metrics = rendon_hd[[\"hit_distance_sc\"]].describe()\n",
    "rendon_hd_metrics = rendon_hd_metrics.rename(columns={\"hit_distance_sc\" : \"Rendon Hit Distance\"})\n",
    "soto_hd_metrics = soto_hd[[\"hit_distance_sc\"]].describe()\n",
    "soto_hd_metrics = soto_hd_metrics.rename(columns={\"hit_distance_sc\" : \"Soto Hit Distance\"})\n",
    "frames = [bregman_hd_metrics,rendon_hd_metrics,soto_hd_metrics]\n",
    "hd_stats = pd.concat(frames, axis = 1)\n",
    "hd_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 2 Step 3: Visualize Hit Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "ax = sns.boxplot(x=\"batter\", y=\"hit_distance_sc\", data=filterd_hd)\n",
    "ax.set(xlabel='Player', ylabel='Hit Distance (ft)')\n",
    "plt.savefig(\"static/images/hit_distance_boxplot.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Soto seems to have the longest hit distances, but need to confirm if this is statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 2 Step 4: Determine if there is a statistical difference in the hit distance between players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj2 Step 4a: Determine if the data is normally distrbuted using graphical approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs1 = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(20, 10))\n",
    "sns.distplot(bregman_hd[\"hit_distance_sc\"], color='tab:blue', ax=axs1[0]).set_title('Alex Bregman \\n Hit Distance, 2019')\n",
    "sns.distplot(rendon_hd[\"hit_distance_sc\"], color='tab:blue', ax=axs1[1]).set_title('Anthony Rendon \\n Hit Distance, 2019')\n",
    "sns.distplot(soto_hd[\"hit_distance_sc\"], color='tab:blue', ax=axs1[2]).set_title('Juan Soto \\n Hit Distance, 2019')\n",
    "fig1.savefig(\"static/images/hit_distance_distplot.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curves appear normally distributed, but need to follow up with a shapiro-wilk test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj2 Step 4b:  Determine if the data is normally distrbuted using Shapiro-Wilk Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scipy.stats.shapiro test for normality\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution.\n",
    "# Bregman\n",
    "breg_sw_test = [stats.shapiro(bregman_hd[\"hit_distance_sc\"])[0], stats.shapiro(bregman_hd[\"hit_distance_sc\"])[1]]\n",
    "rendon_sw_test = [stats.shapiro(rendon_hd[\"hit_distance_sc\"])[0], stats.shapiro(rendon_hd[\"hit_distance_sc\"])[1]]\n",
    "soto_sw_test = [stats.shapiro(soto_hd[\"hit_distance_sc\"])[0], stats.shapiro(soto_hd[\"hit_distance_sc\"])[1]]\n",
    "Shapiro_Wilk_df = pd.DataFrame({\"bregman\": breg_sw_test, \"rendon\": rendon_sw_test, \"soto\": soto_sw_test}, index = [\"W\", \"p-value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The p-value for the test does not reject the Ho. Data is normally distributed\n",
    "Shapiro_Wilk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-values for all the players Shapiro-Wilk test are above 0.05, which suggest that we cannot reject the null hypothesis that the samples came from a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj2 Step 4c: Test for equal variance  using the Barlette's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for equal variance\n",
    "# scipy.stats.bartlett because I know the samples are normally distributed\n",
    "barlette_result = stats.bartlett(bregman_hd[\"hit_distance_sc\"], rendon_hd[\"hit_distance_sc\"], soto_hd[\"hit_distance_sc\"])\n",
    "if barlette_result[1] >= 0.05:\n",
    "    print(\"Do not reject the null hypothesis, the all input samples are from populations with equal variances.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis, the samples do not have equal variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The home run distance data is parametric and we can use an ANOVA to determine if there is a difference in the hit distance between players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj2 Step 4d: Conduct an ANOVA Test for Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The conditions to test an ANOVA have been met\n",
    "anova_hd = stats.f_oneway(bregman_hd[\"hit_distance_sc\"], rendon_hd[\"hit_distance_sc\"], soto_hd[\"hit_distance_sc\"])\n",
    "if anova_hd[1] >= 0.05:\n",
    "    print(f\"The p-value is: {anova_hd[1]}. Do not reject the null hypothesis, no difference in hit distance amongst batters.\")\n",
    "else:\n",
    "    print(f\"The p-value is: {anova_hd[1]}. Reject the null hypothesis, there is a difference in the hit distance amongs batters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj2 Step 4e: Conduct a Post hoc test using Tukey's to determine which variables differ significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "sp.posthoc_tukey(filterd_hd, val_col='hit_distance_sc', group_col='batter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference in the hit distance between \n",
    " - Bregman and Rendon\n",
    " - Bregman and Soto\n",
    " - Rendon and Bregman\n",
    " - Soto and Bregman<br>\n",
    "This suggets that Both Rendon and Soto have a higher hit distance than Bregman, but no difference between Soto and Rendon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 3: Determine the impact of launch speed and launch angle on Home Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 3 Step 1: Use Logistic Regression to determine if launch speed and launch angle can be used to predict home runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 1a: Prepare Data for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database using the .connect() method\n",
    "# This will only connect to the website data, once you save the data as either a csv or db, \n",
    "# you will need to reconnect with the correct filepath\n",
    "conn = sqlite3.connect('/Users/trinitycisneros/Documents/Coding/bitterscientist.com/statcast.db')\n",
    "season2019_df = pd.read_sql_query(\"SELECT events, launch_angle, launch_speed FROM statcast;\", conn)\n",
    "season2019_df.to_csv('/Users/trinitycisneros/Documents/Coding/bitterscientist.com/season2019_logreg')\n",
    "conn.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data (remove nan, and change datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows that have missing values, as we can't use this data in the analysis\n",
    "season2019_df = season2019_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will change datatypes columns\n",
    "float_cols = ['launch_angle','launch_speed']\n",
    "cat_col = ['events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts columns into floats\n",
    "for col in float_cols:\n",
    "    season2019_df[col] = season2019_df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert events column into category\n",
    "for col in cat_col:\n",
    "    season2019_df[col] = season2019_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for analysis, use .get_dummies() to get binary array for each event\n",
    "dummy_df = pd.get_dummies(season2019_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe \n",
    "dummy_df = dummy_df[['launch_angle', 'launch_speed', 'events_home_run']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all events\n",
    "ax = sns.scatterplot(x=\"launch_speed\", y=\"launch_angle\", hue=\"events_home_run\", data=dummy_df)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.90), ncol=1)\n",
    "plt.savefig(\"static/images/events_home_run.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign predictor variables to X and target variable to y\n",
    "X = dummy_df[['launch_angle', 'launch_speed']]\n",
    "y = dummy_df['events_home_run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='rbf', gamma=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on trainig set: 0.97\n",
      "Accuracy on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on trainig set: {:.2f}\".format(svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35970,   427,   658,  1403])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35970 427 658 1403\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36397\n",
      "           1       0.77      0.68      0.72      2061\n",
      "\n",
      "    accuracy                           0.97     38458\n",
      "   macro avg       0.87      0.83      0.85     38458\n",
      "weighted avg       0.97      0.97      0.97     38458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.949\n",
      "Test set score: 0.952\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "logreg = LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Apply fitted model with test values\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix to evaluate the accuracy of a classification\n",
    "log_cm = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36082 315 1538 523\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = log_cm\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(cmm, annot=True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# clf = svm.SVC(kernel='linear', C = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel=’poly’, degree=6).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for analysis, use .get_dummies() to get binary array for each event\n",
    "logreg_data = results[[\"events\", 'launch_angle', 'launch_speed']]\n",
    "dum_logreg_data = pd.get_dummies(logreg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows that have missing values, as we can't use this data in the analysis\n",
    "dum_logreg_data = dum_logreg_data[['launch_angle','launch_speed','events_home_run']].dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign predictor variables to X and target variable to y\n",
    "X = dum_logreg_data[['launch_angle', 'launch_speed']]\n",
    "y = dum_logreg_data['events_home_run']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 1b: Conduct the logistic regression analysis and use the .train_test_split() method to evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the LogisticRegression model, the solver parameter is set to default algorithm\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Fit the data to the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fitted model with test values\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix to evaluate the accuracy of a classification\n",
    "test_cm = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = test_cm\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 421 correct predictions and 35 incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine the accuracy of the classifier in classifying the data points \n",
    "# using the .classification_report() method\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 1c:  Plot the roc_curve\n",
    " - a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied, the farther left from the red dotted line, the better the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('static/images/Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 1d:  Test Model using data from a separate player not used in building the logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in CSV file containing the data for Springer (Houston Astros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "springer = pd.read_csv('static/documents/springer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minor data cleaning\n",
    "springer['batter'].replace({543807: 'Springer'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for analysis, use .get_dummies() to get binary array for each event\n",
    "springer_data = springer[[\"events\", 'launch_angle', 'launch_speed']].sample(frac=1)\n",
    "springer_test_data = pd.get_dummies(springer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "springer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows that have missing values, as we can't use this data in the analysis\n",
    "springer_test_data = springer_test_data[['launch_angle','launch_speed','events_home_run']].dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of batted events\n",
    "print(f\"Springer had a total number batted events: {len(springer_test_data['events_home_run'])}\")\n",
    "print(f\"Springer's total number of home runs: {len(springer_test_data[springer_test_data['events_home_run'] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign predictor variables to X and target variable to y\n",
    "X_validation = springer_test_data[['launch_angle', 'launch_speed']]\n",
    "y_validation = springer_test_data['events_home_run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fitted model with test values\n",
    "y_pred_validation = logreg.predict(X_validation)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix to evaluate the accuracy of a classification\n",
    "tn, fp, fn, tp = confusion_matrix(y_validation, y_pred_validation).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_validation, logreg.predict(X_validation))\n",
    "fpr, tpr, thresholds = roc_curve(y_validation, logreg.predict_proba(X_validation)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('static/images/Log_ROC_validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 3 Step 2: Assess the Launch Speed and Launch Angle for each player\n",
    " - These two variables have been reported to play an important role in home run events\n",
    " - This data uses the results dataframe that combines all players and drops any missing event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alex Bregman batted events by launch speed and launch angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alex Bregman\n",
    "fig1, axs1 = plt.subplots(ncols=1, sharex=True, sharey=True, figsize=(10, 10))\n",
    "sns.set(font_scale=1.25)\n",
    "sns.scatterplot(x=\"launch_speed\", y=\"launch_angle\", hue=\"events\", data= results[results[\"batter\"] == \"Bregman\"]).set_title('Alex Bregman\\nBatter Events, 2019')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.45, 1), ncol=1)\n",
    "fig1.savefig(\"static/images/bregman_events_angle_speed.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The home runs appear clustered between 20-40 angles and above 90 mph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Athony Rendon batted events by launch speed and launch angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthony Rendon\n",
    "fig1, axs1 = plt.subplots(ncols=1, sharex=True, sharey=True, figsize=(10, 10))\n",
    "sns.set(font_scale=1.25)\n",
    "sns.scatterplot(x=\"launch_speed\", y=\"launch_angle\", hue=\"events\", data= results[results[\"batter\"] == \"Rendon\"]).set_title('Anthony Rendon\\nBatter Events, 2019')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.45, 1), ncol=1)\n",
    "fig1.savefig(\"static/images/rendon_events_angle_speed.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The home runs appear clustered between 20-40 angles and above 95 mph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juan Soto batted events by launch speed and launch angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juan Soto\n",
    "fig1, axs1 = plt.subplots(ncols=1, sharex=True, sharey=True, figsize=(10, 10))\n",
    "sns.set(font_scale=1.25)\n",
    "sns.scatterplot(x=\"launch_speed\", y=\"launch_angle\", hue=\"events\", data= results[results[\"batter\"] == \"Soto\"]).set_title('Juan Soto\\nBatter Events, 2019')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.45, 1), ncol=1)\n",
    "fig1.savefig(\"static/images/soto_events_angle_speed.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The home runs appear clustered between 20-40 angles and above 100 mph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 3 Step 3: Evaluate Home Run Data\n",
    " - To focus on the launch angle and speed in home run activity\n",
    " - Data used here is the original dataframe that was imported from CSV\n",
    " - this data does not have any event filtered, but thats because a home run is an event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 3a: Filter data by player and by home runs\n",
    " - use this method because we don't have to go through a series of filters using the combined results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to include home runs only\n",
    "bregman_hr = bregman[bregman[\"events\"] == \"home_run\"]\n",
    "rendon_hr = rendon[rendon[\"events\"] == \"home_run\"]\n",
    "soto_hr = soto[soto[\"events\"] == \"home_run\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 3b: Compare the descriptive statistics for speed and launch angle\n",
    " -  Combine descriptive statistics by player into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bregman_hr_metrics = bregman_hr[[\"launch_speed\", \"launch_angle\"]].describe()\n",
    "bregman_hr_metrics = bregman_hr_metrics.rename(columns={\"launch_speed\" : \"Bregman Speed\", \"launch_angle\": \"Bregman Angle\"})\n",
    "rendon_hr_metrics = rendon_hr[[\"launch_speed\", \"launch_angle\"]].describe()\n",
    "rendon_hr_metrics = rendon_hr_metrics.rename(columns={\"launch_speed\" : \"Rendon Speed\", \"launch_angle\": \"Rendon Angle\"})\n",
    "soto_hr_metrics = soto_hr[[\"launch_speed\", \"launch_angle\"]].describe()\n",
    "soto_hr_metrics = soto_hr_metrics.rename(columns={\"launch_speed\" : \"Soto Speed\", \"launch_angle\": \"Soto Angle\"})\n",
    "frames = [bregman_hr_metrics,rendon_hr_metrics,soto_hr_metrics]\n",
    "hr_stats = pd.concat(frames, axis = 1)\n",
    "hr_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 3c:  Visualize the launch angle and launch speed for home runs by player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with three scatter plots of launch speed vs. launch angle, one for each player's home runs\n",
    "fig1, axs1 = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(10, 5))\n",
    "sns.set(font_scale=1)\n",
    "sns.regplot(x=bregman_hr[\"launch_speed\"], y=bregman_hr[\"launch_angle\"], fit_reg=False, color='tab:blue', data=bregman_hr, ax=axs1[0]).set_title('Alex Bregman\\nHome Runs, 2019')\n",
    "sns.regplot(x=rendon_hr[\"launch_speed\"], y=rendon_hr[\"launch_angle\"], fit_reg=False, color='tab:blue', data=rendon_hr, ax=axs1[1]).set_title('Anthony Rendon\\nHome Runs, 2019')\n",
    "sns.regplot(x=soto_hr[\"launch_speed\"], y=soto_hr[\"launch_angle\"], fit_reg=False, color='tab:blue', data=soto_hr, ax=axs1[2]).set_title('Juan Soto\\nHome Runs, 2019')\n",
    "fig1.savefig(\"static/images/angle_speed.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 3 Step 4: Conduct statistical analysis to determine if launch speed differs among players\n",
    " - does speed explain the difference in the difference in home runs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 4a: test for normality using Shapiro-Wilk Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scipy.stats.shapiro test for normality\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution.\n",
    "# Bregman\n",
    "breg_sw_speed_test = [stats.shapiro(bregman_hd[\"launch_speed\"])[0], stats.shapiro(bregman_hd[\"launch_speed\"])[1]]\n",
    "rendon_sw_speed_test = [stats.shapiro(rendon_hd[\"launch_speed\"])[0], stats.shapiro(rendon_hd[\"launch_speed\"])[1]]\n",
    "soto_sw_speed_test = [stats.shapiro(soto_hd[\"launch_speed\"])[0], stats.shapiro(soto_hd[\"launch_speed\"])[1]]\n",
    "Shapiro_Wilk_speed_df = pd.DataFrame({\"bregman\": breg_sw_speed_test, \"rendon\": rendon_sw_speed_test, \"soto\": soto_sw_speed_test}, index = [\"W\", \"p-value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The launch speed for Anthony Rendon does not seem to follow a normal distribution, as the p-value < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 4b: test the launch angle for normality using Shapiro-Wilk Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scipy.stats.shapiro test for normality\n",
    "# The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution.\n",
    "# Bregman\n",
    "breg_sw_angle_test = [stats.shapiro(bregman_hd[\"launch_angle\"])[0], stats.shapiro(bregman_hd[\"launch_angle\"])[1]]\n",
    "rendon_sw_angle_test = [stats.shapiro(rendon_hd[\"launch_angle\"])[0], stats.shapiro(rendon_hd[\"launch_angle\"])[1]]\n",
    "soto_sw_angle_test = [stats.shapiro(soto_hd[\"launch_angle\"])[0], stats.shapiro(soto_hd[\"launch_angle\"])[1]]\n",
    "Shapiro_Wilk_angle_df = pd.DataFrame({\"bregman\": breg_sw_angle_test, \"rendon\": rendon_sw_angle_test, \"soto\": soto_sw_angle_test}, index = [\"W\", \"p-value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shapiro_Wilk_angle_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test confirms that the launch angle is normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 4c: determine if samples have equal variance using Barlette's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for equal variance\n",
    "# scipy.stats.bartlett because I know the samples are normally distributed\n",
    "barlette_angle = stats.bartlett(bregman_hd[\"launch_angle\"], rendon_hd[\"launch_angle\"], soto_hd[\"launch_angle\"])\n",
    "if barlette_angle[1] >= 0.05:\n",
    "    print(\"Do not reject the null hypothesis, all the input samples are from a populations with equal variances.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis, the samples do not have equal variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 4d: Conduct an ANOVA to determine if there is a significant differnece in the angles between players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The conditions to test an ANOVA have been met\n",
    "anova_angle = stats.f_oneway(bregman_hd[\"launch_angle\"], rendon_hd[\"launch_angle\"], soto_hd[\"launch_angle\"])\n",
    "if anova_angle[1] >= 0.05:\n",
    "    print(f\"The p-value is: {anova_angle[1]}. Do not reject the null hypothesis, no difference in launch angle amongst batters.\")\n",
    "else:\n",
    "    print(f\"The p-value is: {anova_angle[1]}. Reject the null hypothesis, there is a difference in the launch angle amongs batters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 4e: Calculate the Pearson Correlation for those conditions that are normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pearson coefficient and p-value Bregman\n",
    "bregman_pearson = stats.pearsonr(bregman_hr[\"launch_speed\"], bregman_hr[\"launch_angle\"])\n",
    "bregman_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pearson coefficient and p-value Soto\n",
    "soto_pearson = stats.pearsonr(soto_hr[\"launch_speed\"], soto_hr[\"launch_angle\"])\n",
    "soto_pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 4f: Calculate the Spearman R for those conditions that are not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bregman_spearmanr = stats.spearmanr(bregman_hr[\"launch_speed\"], bregman_hr[\"launch_angle\"])\n",
    "rendon_spearmanr = stats.spearmanr(rendon_hr[\"launch_speed\"], rendon_hr[\"launch_angle\"])\n",
    "soto_spearmanr = stats.spearmanr(soto_hr[\"launch_speed\"], soto_hr[\"launch_angle\"])\n",
    "player_spearmanr = pd.DataFrame({\"bregman\": bregman_spearmanr, \"rendon\": rendon_spearmanr, \"soto\": soto_spearmanr}, index = [\"rho\", \"p-value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p value for breman suggest that it is statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj 3 Step 5: Visualize Launch Speed vs Launch Angle in Home Run Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 5a: Alex Bregman plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bregman\n",
    "sns.jointplot(x='launch_speed',y='launch_angle',data=bregman_hr, kind='reg')\n",
    "plt.savefig(\"static/images/bregman_join_plot_angle_speed.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 5a: Anthony Rendon plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendon\n",
    "sns.jointplot(x='launch_speed',y='launch_angle',data=rendon_hr, kind='reg')\n",
    "plt.savefig(\"static/images/rendon_join_plot_angle_speed.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 3 Step 5a: Juan Soto plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soto\n",
    "sns.jointplot(x='launch_speed',y='launch_angle',data=soto_hr, kind='reg')\n",
    "plt.savefig(\"static/images/soto_join_plot_angle_speed.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj3 Step 6: Compute the Kruskal-Wallis H-test for independent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal_wallis_h = stats.kruskal(bregman_hd[\"launch_speed\"], rendon_hd[\"launch_speed\"], soto_hd[\"launch_speed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kruskal_wallis_h[1] >= 0.05:\n",
    "    print(f\"The p value is : {kruskal_wallis_h}. Do not reject the null hypothesis, no difference in the launch speed amongst batters.\")\n",
    "else:\n",
    "    print(f\"The p value is : {kruskal_wallis_h} Reject the null hypothesis, there is a difference in the launch speed amongs batters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj3 Step 7 Post hoc test using scikit-posthocs 0.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dunn = sp.posthoc_dunn(filterd_hd, val_col=\"launch_speed\", group_col='batter', p_adjust = 'holm')\n",
    "dunn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no difference in the launch angle between players<br>\n",
    "The launch speed between \n",
    " - Soto and Bregman is significantlly different\n",
    " - Rendon and Soto is significantly different<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 4: Determine the impact of pitch velocity on Home Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 4 Step 4a: Summary Statistics for the pitch velocity \"release_speed\" for each event that results in a home run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the player_hr dataframe because it has been filtered for home run events\n",
    "\n",
    "# Bregman\n",
    "bregman_hr_rs = bregman_hr[[\"release_speed\"]].describe()\n",
    "bregman_hr_rs = bregman_hr_rs.rename(columns={\"release_speed\" : \"Bregman rs\"})\n",
    "\n",
    "# Rendon\n",
    "rendon_hr_rs = rendon_hr[[\"release_speed\"]].describe()\n",
    "rendon_hr_rs = rendon_hr_rs.rename(columns={\"release_speed\" : \"Rendon rs\"})\n",
    "\n",
    "# Soto\n",
    "soto_hr_rs = soto_hr[[\"release_speed\"]].describe()\n",
    "soto_hr_rs = soto_hr_rs.rename(columns={\"release_speed\" : \"Soto rs\"})\n",
    "\n",
    "# Combine summary stats into a single table\n",
    "frames = [bregman_hr_rs,rendon_hr_rs,soto_hr_rs]\n",
    "rs_stats = pd.concat(frames, axis = 1)\n",
    "rs_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as if Soto bats against higher pitch velocities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 4 Step 4b: Visualize distribution of pitch velocity for each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot that describes the pitch velocity of each player's home runs\n",
    "fig1, axs1 = plt.subplots(ncols=3, sharex=True, sharey=True, figsize=(15, 7.5))\n",
    "sns.boxplot(bregman_hr[\"release_speed\"], color='tab:blue', ax=axs1[0]).set_title('Alex Bregman \\n Home Runs, 2019')\n",
    "sns.boxplot(rendon_hr[\"release_speed\"], color='tab:blue', ax=axs1[1]).set_title('Anthony Rendon \\n Home Runs, 2019')\n",
    "sns.boxplot(soto_hr[\"release_speed\"], color='tab:blue', ax=axs1[2]).set_title('Juan Soto \\n Home Runs, 2019')\n",
    "fig1.savefig(\"static/images/release_speed.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 4 Step 4c: Determine if the release_speed differes for all batted events between players (in other words, did any player have to hit the ball against faster, or slower pitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the entire dataset for this one, but dropped any instance that \n",
    "# does not have a release_speed associated\n",
    "results_rs = result.dropna(how='any', subset=['release_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filterd by player\n",
    "bregman_rs = results_rs[results_rs[\"batter\"] == \"Bregman\"][\"release_speed\"]\n",
    "rendon_rs = results_rs[results_rs[\"batter\"] == \"Rendon\"][\"release_speed\"]\n",
    "soto_rs = results_rs[results_rs[\"batter\"] == \"Soto\"][\"release_speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anova\n",
    "anova_rs = stats.f_oneway(bregman_rs, rendon_rs, soto_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if anova_rs[1] >= 0.05:\n",
    "    print(\"Do not reject the null hypothesis, no difference in the pitch velocity amongst batters.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis, there is a difference in the pitch velocity amongs batters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 4 Step 4d: Conduct a post hoc test to determine which players here significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [bregman_hd[\"launch_speed\"], rendon_hd[\"launch_speed\"], soto_hd[\"launch_speed\"]]\n",
    "dunn = sp.posthoc_dunn(results_rs, val_col=\"release_speed\", group_col='batter', p_adjust = 'holm')\n",
    "dunn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference in the pitch velocity between Soto and Rendon<br>\n",
    "No difference in the pitch velocity between:\n",
    " - Bregman and Rendon\n",
    " - Bregman and Soto<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obj 5: Determine the Player's Pitch Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 5 Step 1: Functions to assign the x and y coordinate for the pitch location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_x_coord(row):\n",
    "    \"\"\"\n",
    "    Assigns an x-coordinate to Statcast's strike zone numbers. Zones 11, 12, 13,\n",
    "    and 14 are ignored for plotting simplicity.\n",
    "    \"\"\"\n",
    "    # Left third of strike zone\n",
    "    if row.zone in [1, 4, 7]:\n",
    "        return 1\n",
    "    # Middle third of strike zone\n",
    "    if row.zone in [2, 5, 8]:\n",
    "        return 2\n",
    "    # Right third of strike zone\n",
    "    if row.zone in [3, 6, 9]:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_y_coord(row):\n",
    "    \"\"\"\n",
    "    Assigns a y-coordinate to Statcast's strike zone numbers. Zones 11, 12, 13,\n",
    "    and 14 are ignored for plotting simplicity.\n",
    "    \"\"\"\n",
    "    # Upper third of strike zone\n",
    "    if row.zone in [1, 2, 3]:\n",
    "        return 3\n",
    "    # Middle third of strike zone\n",
    "    if row.zone in [4, 5, 6]:\n",
    "        return 2\n",
    "    # Lower third of strike zone\n",
    "    if row.zone in [7, 8, 9]:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 5 Step 2a:  Alex Bregman's home run zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zones 11, 12, 13, and 14 are to be ignored for plotting simplicity\n",
    "bregman_strikes_hr = bregman_hr.copy().loc[bregman_hr.zone <= 9]\n",
    "\n",
    "# Assign Cartesian coordinates to pitches in the strike zone for Judge home runs\n",
    "bregman_strikes_hr['zone_x'] = bregman_strikes_hr.apply(assign_x_coord, axis=1)\n",
    "bregman_strikes_hr['zone_y'] = bregman_strikes_hr.apply(assign_y_coord, axis=1)\n",
    "\n",
    "# Plot Judge's home run zone as a 2D histogram with a colorbar\n",
    "plt.hist2d(bregman_strikes_hr['zone_x'], bregman_strikes_hr['zone_y'], bins = 3, cmap='Blues')\n",
    "plt.title('Alex Bregman Home Runs on\\n Pitches in the Strike Zone, 2019')\n",
    "plt.gca().get_xaxis().set_visible(False)\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Counts in Bin')\n",
    "\n",
    "plt.savefig(\"static/images/bregman_hr_zone.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obj 5 Step 2b:  Anthony Rendons home run zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zones 11, 12, 13, and 14 are to be ignored for plotting simplicity\n",
    "rendon_strike_hr = rendon_hr.copy().loc[rendon_hr.zone <= 9]\n",
    "\n",
    "# Assign Cartesian coordinates to pitches in the strike zone for Stanton home runs\n",
    "rendon_strike_hr['zone_x'] = rendon_strike_hr.apply(assign_x_coord, axis=1)\n",
    "rendon_strike_hr['zone_y'] = rendon_strike_hr.apply(assign_y_coord, axis=1)\n",
    "\n",
    "# Plot Stanton's home run zone as a 2D histogram with a colorbar\n",
    "plt.hist2d(rendon_strike_hr['zone_x'], rendon_strike_hr['zone_y'], bins = 3, cmap='Blues')\n",
    "plt.title('Anthony Rendon Home Runs on\\n Pitches in the Strike Zone, 2019')\n",
    "plt.gca().get_xaxis().set_visible(False)\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Counts in Bin')\n",
    "# Save file\n",
    "plt.savefig(\"static/images/rendon_hr_zone.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### Obj 5 Step 2c:  Juan Soto's home run zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zones 11, 12, 13, and 14 are to be ignored for plotting simplicity\n",
    "soto_strike_hr = soto_hr.copy().loc[soto_hr.zone <= 9]\n",
    "\n",
    "# Assign Cartesian coordinates to pitches in the strike zone for Stanton home runs\n",
    "soto_strike_hr['zone_x'] = soto_strike_hr.apply(assign_x_coord, axis=1)\n",
    "soto_strike_hr['zone_y'] = soto_strike_hr.apply(assign_y_coord, axis=1)\n",
    "\n",
    "# Plot Stanton's home run zone as a 2D histogram with a colorbar\n",
    "plt.hist2d(soto_strike_hr['zone_x'], soto_strike_hr['zone_y'], bins = 3, cmap='Blues')\n",
    "plt.title('Jose Soto Home Runs on\\n Pitches in the Strike Zone, 2019')\n",
    "plt.gca().get_xaxis().set_visible(False)\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Counts in Bin')\n",
    "# Save file\n",
    "plt.savefig(\"static/images/soto_hr_zone.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
