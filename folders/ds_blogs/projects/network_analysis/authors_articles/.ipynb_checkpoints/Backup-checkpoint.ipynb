{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34901096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da2ab4",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876b31d",
   "metadata": {},
   "source": [
    "<h1>Import Packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dfcc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5c5ba",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20190f",
   "metadata": {},
   "source": [
    "<h1>Import Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab45ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"authors_data.xlsx\"\n",
    "df = pd.read_excel(file, sheet_name=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001d5c7",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731f34d",
   "metadata": {},
   "source": [
    "<h1>Inspect Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c103900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Degree Discipline</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Has_Contributors</th>\n",
       "      <th>Co-ID</th>\n",
       "      <th>Contributor Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>‘Vaccine Deserts’ Threaten to Prolong COVID-19...</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-917</td>\n",
       "      <td>Sara Kim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>‘Vaccine Deserts’ Threaten to Prolong COVID-19...</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-506</td>\n",
       "      <td>Amanda Nguyen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>‘Vaccine Deserts’ Threaten to Prolong COVID-19...</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-204</td>\n",
       "      <td>Jeroen van Meijgaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>800+ Drugs Became More Expensive This January ...</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-204</td>\n",
       "      <td>Jeroen van Meijgaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>Anxiety and Depression Medication Prices Have ...</td>\n",
       "      <td>2019-09-10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-204</td>\n",
       "      <td>Jeroen van Meijgaard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID      Author Degree         Degree Discipline  \\\n",
       "0  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "1  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "2  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "3  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "4  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "\n",
       "                                               Title       Date  \\\n",
       "0  ‘Vaccine Deserts’ Threaten to Prolong COVID-19... 2021-01-14   \n",
       "1  ‘Vaccine Deserts’ Threaten to Prolong COVID-19... 2021-01-14   \n",
       "2  ‘Vaccine Deserts’ Threaten to Prolong COVID-19... 2021-01-14   \n",
       "3  800+ Drugs Became More Expensive This January ... 2021-02-02   \n",
       "4  Anxiety and Depression Medication Prices Have ... 2019-09-10   \n",
       "\n",
       "  Has_Contributors   Co-ID      Contributor Name  \n",
       "0              Yes  ID-917              Sara Kim  \n",
       "1              Yes  ID-506         Amanda Nguyen  \n",
       "2              Yes  ID-204  Jeroen van Meijgaard  \n",
       "3              Yes  ID-204  Jeroen van Meijgaard  \n",
       "4              Yes  ID-204  Jeroen van Meijgaard  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9519a695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID-121</th>\n",
       "      <th>Tori Marsh</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-204</th>\n",
       "      <th>Jeroen van Meijgaard</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-400</th>\n",
       "      <th>Diane Li</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-471</th>\n",
       "      <th>Lauren Chase</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-506</th>\n",
       "      <th>Amanda Nguyen</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-610</th>\n",
       "      <th>Sasha Guttentag</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title\n",
       "ID     Author                     \n",
       "ID-121 Tori Marsh               69\n",
       "ID-204 Jeroen van Meijgaard      9\n",
       "ID-400 Diane Li                 15\n",
       "ID-471 Lauren Chase             42\n",
       "ID-506 Amanda Nguyen            21\n",
       "ID-610 Sasha Guttentag          10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = df.groupby(by=[\"ID\", \"Author\"])[\"Title\"].count().to_frame()\n",
    "authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42b066",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfabacf",
   "metadata": {},
   "source": [
    "<h1>Text K-means Clustering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f34fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words={'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df.Title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df146919",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ecfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f7864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(2,10)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, max_iter=200, n_init=10)\n",
    "    km = km.fit(X)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37412860",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=200, n_init=10)\n",
    "model.fit(X)\n",
    "labels=model.labels_\n",
    "articles_cl=pd.DataFrame(list(zip(titles,labels)),columns=['titles','cluster'])\n",
    "print(articles_cl.sort_values(by=['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "result={'cluster':labels,'authors':titles}\n",
    "result=pd.DataFrame(result)\n",
    "for k in range(0,true_k):\n",
    "    s=result[result.cluster==k]\n",
    "    text=s['authors'].str.cat(sep=' ')\n",
    "    text=text.lower()\n",
    "    text=' '.join([word for word in text.split()])\n",
    "    wordcloud = WordCloud(max_font_size=50, max_words=10, background_color=\"white\").generate(text)\n",
    "    print('Cluster: {}'.format(k))\n",
    "    print('Titles')\n",
    "    titles=articles_cl[articles_cl.cluster==k]['titles']\n",
    "    print(titles.to_string(index=False))\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84776a7b",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228810c0",
   "metadata": {},
   "source": [
    "<h1>Word Clouds from Dataframe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9deeb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/trinidadcisneros/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/trinidadcisneros/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/trinidadcisneros/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Import Natural Language Toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a1b52",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52337b",
   "metadata": {},
   "source": [
    "# Group All Titles by Author ID\n",
    "\n",
    " - Drop Duplicates\n",
    " - Group by and combine titles by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0784e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Degree Discipline</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Has_Contributors</th>\n",
       "      <th>Co-ID</th>\n",
       "      <th>Contributor Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>‘Vaccine Deserts’ Threaten to Prolong COVID-19...</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-204</td>\n",
       "      <td>Jeroen van Meijgaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>800+ Drugs Became More Expensive This January ...</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-204</td>\n",
       "      <td>Jeroen van Meijgaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>Anxiety and Depression Medication Prices Have ...</td>\n",
       "      <td>2019-09-10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-262</td>\n",
       "      <td>Clement B Feyt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>Can’t Access Generic Humalog? There’s an Even ...</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-204</td>\n",
       "      <td>Jeroen van Meijgaard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>MPH</td>\n",
       "      <td>Drug pricing and savings</td>\n",
       "      <td>COVID-19 Causes a Drop in Fills for HIV Preven...</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ID-471</td>\n",
       "      <td>Lauren Chase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID      Author Degree         Degree Discipline  \\\n",
       "2  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "3  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "6  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "8  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "9  ID-121  Tori Marsh    MPH  Drug pricing and savings   \n",
       "\n",
       "                                               Title       Date  \\\n",
       "2  ‘Vaccine Deserts’ Threaten to Prolong COVID-19... 2021-01-14   \n",
       "3  800+ Drugs Became More Expensive This January ... 2021-02-02   \n",
       "6  Anxiety and Depression Medication Prices Have ... 2019-09-10   \n",
       "8  Can’t Access Generic Humalog? There’s an Even ... 2019-08-26   \n",
       "9  COVID-19 Causes a Drop in Fills for HIV Preven... 2020-10-20   \n",
       "\n",
       "  Has_Contributors   Co-ID      Contributor Name  \n",
       "2              Yes  ID-204  Jeroen van Meijgaard  \n",
       "3              Yes  ID-204  Jeroen van Meijgaard  \n",
       "6              Yes  ID-262        Clement B Feyt  \n",
       "8              Yes  ID-204  Jeroen van Meijgaard  \n",
       "9              Yes  ID-471          Lauren Chase  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_titles_df = df.drop_duplicates(subset=['Title'], keep='last')\n",
    "author_titles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75d270d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID-121</td>\n",
       "      <td>Tori Marsh</td>\n",
       "      <td>‘Vaccine Deserts’ Threaten to Prolong COVID-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID-204</td>\n",
       "      <td>Jeroen van Meijgaard</td>\n",
       "      <td>Drug Makers Keep Promises to Limit Price Incre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID-400</td>\n",
       "      <td>Diane Li</td>\n",
       "      <td>A Look at Medicare Part D Plans in 2020: Highe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID-471</td>\n",
       "      <td>Lauren Chase</td>\n",
       "      <td>A Guide to Biosimilar Prices: How Much They Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID-506</td>\n",
       "      <td>Amanda Nguyen</td>\n",
       "      <td>25 Million Americans Have Lost Their Health In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID-610</td>\n",
       "      <td>Sasha Guttentag</td>\n",
       "      <td>Almost 60% of the Public Plans to Get the COVI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                Author  \\\n",
       "0  ID-121            Tori Marsh   \n",
       "1  ID-204  Jeroen van Meijgaard   \n",
       "2  ID-400              Diane Li   \n",
       "3  ID-471          Lauren Chase   \n",
       "4  ID-506         Amanda Nguyen   \n",
       "5  ID-610       Sasha Guttentag   \n",
       "\n",
       "                                               Title  \n",
       "0  ‘Vaccine Deserts’ Threaten to Prolong COVID-19...  \n",
       "1  Drug Makers Keep Promises to Limit Price Incre...  \n",
       "2  A Look at Medicare Part D Plans in 2020: Highe...  \n",
       "3  A Guide to Biosimilar Prices: How Much They Co...  \n",
       "4  25 Million Americans Have Lost Their Health In...  \n",
       "5  Almost 60% of the Public Plans to Get the COVI...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_titles = author_titles_df.groupby(['ID', 'Author'], as_index = False).agg({'Title': ' '.join})\n",
    "author_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e6b05",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b1344",
   "metadata": {},
   "source": [
    "# Word Tokenization\n",
    "\n",
    " - Action: Return a tokenized copy of string\n",
    " - word_tokenize(string)\n",
    " - Documentation: https://www.nltk.org/_modules/nltk/tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e3e60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lists that contain tokens for each word in each list\n",
    "word_tokens = [word_tokenize(text) for text in author_titles.Title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f488d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token processing, remove non alpha numeric tokens from each list\n",
    "cleaned_tokens = [[word for word in item if word.isalnum()] for item in word_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "973aaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to dataframe\n",
    "author_titles[\"tokens\"] = cleaned_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab9ac3",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb7d28",
   "metadata": {},
   "source": [
    "# Word Token Lemmatizing\n",
    "\n",
    " - Action: Lemmatization is the process of converting a word to its base form.\n",
    " - WNlemmatizer = WordNetLemmatizer()\n",
    " - lemmanized = WNlemmatizer.lemmatize(token)\n",
    " - Documentation: https://www.nltk.org/_modules/nltk/stem/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee703353",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_list = []\n",
    "WNlemmatizer = WordNetLemmatizer()\n",
    "for index, series in author_titles[\"tokens\"].iteritems():\n",
    "    lemm_list.append([WNlemmatizer.lemmatize(token).lower() for token in series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a0b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_titles[\"lemm_tokens\"] = lemm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf47a17",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dcd34",
   "metadata": {},
   "source": [
    "# WordCloud Analysis\n",
    "\n",
    " - Reveals essential\n",
    " - Provides an overall sense of the text\n",
    " - Easy to grasp and engaging\n",
    " - wordcloud = WordCloud().generate(text)\n",
    " - Documentation: https://amueller.github.io/word_cloud/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c5d0e",
   "metadata": {},
   "source": [
    "## Step 1: Filter Text Using Custom Stop Word List\n",
    "\n",
    " - Combine stop words from wordcloud, nltk, and custom list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b75fc998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of stop words in custom list is: 250\n"
     ]
    }
   ],
   "source": [
    "# Wordcloud stopwords\n",
    "wc_sw = STOPWORDS\n",
    "custom_sps = set(['made', 'nothing','able', 'given', 'wish', 'willing', 'wa', 'due', 'ha', 'did','etc', 'use', 'really', 'felt', 'personally', 'also', 'thing', 'well', 'little', 'got', 'one', 'lot', 'way', 'jus', 'sure'])\n",
    "cust_nltk_sw = set(stopwords.words('english')).union(custom_sps).union(wc_sw)\n",
    "print(f'The number of stop words in custom list is: {len(cust_nltk_sw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b622229",
   "metadata": {},
   "source": [
    "## Step 2: Visualize WordCloud for all Title by Authors in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f6729",
   "metadata": {},
   "source": [
    "### Step 2a: Create function that converts tokenized text into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f709527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used in the wordcloud\n",
    "def convert_text(series):\n",
    "    np_array = series.array\n",
    "    text = ' '.join(str(v) for v in np_array[0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529dd8d",
   "metadata": {},
   "source": [
    "### Step 2b: Create Wordcloud PNG files for each Author ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ids = author_titles.ID\n",
    "nbr_features = len(author_titles.ID)\n",
    "\n",
    "# for i in range(0,nbr_features):\n",
    "for id_num, num in zip(author_ids, range(0,nbr_features)):\n",
    "    fig = plt.figure(figsize=(30,15))\n",
    "    fig.subplots_adjust(hspace=1, wspace=0.2)\n",
    "\n",
    "    df0=author_titles[author_titles['ID']==id_num]['lemm_tokens']\n",
    "    text = convert_text(df0)\n",
    "    cloud = WordCloud(background_color=\"white\", max_words=10, stopwords=cust_nltk_sw, collocations=False).generate(text)\n",
    "\n",
    "    plt.imshow(cloud, interpolation='bilinear')\n",
    "    plt.title(id_num, fontsize = 20)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{id_num}_wordcloud.png\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e39df",
   "metadata": {},
   "source": [
    "### Step 2c: Create figure that contains all wordclouds, each as a subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe02123",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ids = author_titles.ID\n",
    "nbr_features = len(author_titles.ID)\n",
    "fig = plt.figure(figsize=(30,15))\n",
    "fig.subplots_adjust(hspace=1, wspace=0.2)\n",
    "\n",
    "for id_num, num in zip(author_ids, range(1,nbr_features)):\n",
    "    df0=author_titles[author_titles['ID']==id_num]['lemm_tokens']\n",
    "    text = convert_text(df0)\n",
    "    cloud = WordCloud(background_color=\"white\", max_words=10, stopwords=cust_nltk_sw, collocations=False).generate(text)\n",
    "    ax = fig.add_subplot(4,3, num)\n",
    "    ax.imshow(cloud, interpolation='bilinear')\n",
    "    ax.set_title(id_num)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(f\"all_wordcloud.png\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fdc8ca",
   "metadata": {},
   "source": [
    "## Step 3: Visualize WordCloud for all Titles\n",
    "\n",
    " - Combine All Titles\n",
    " - Generate WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c98ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ' '.join(author_titles_df[\"Title\"])\n",
    "title_list = []\n",
    "title_list.append(titles)\n",
    "title_df = pd.DataFrame.from_dict({'ID': 'ID-All', 'Title' : title_list})\n",
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lists that contain tokens for each word in each list\n",
    "word_tokens = [word_tokenize(text) for text in title_df.Title]\n",
    "\n",
    "# Token processing, remove non alpha numeric tokens from each list\n",
    "cleaned_tokens = [[word for word in item if word.isalnum()] for item in word_tokens]\n",
    "# Add results to dataframe\n",
    "title_df[\"tokens\"] = cleaned_tokens\n",
    "\n",
    "lemm_list = []\n",
    "WNlemmatizer = WordNetLemmatizer()\n",
    "for index, series in title_df[\"tokens\"].iteritems():\n",
    "    lemm_list.append([WNlemmatizer.lemmatize(token).lower() for token in series])\n",
    "\n",
    "title_df[\"lemm_tokens\"] = lemm_list\n",
    "\n",
    "\n",
    "# Wordcloud stopwords\n",
    "wc_sw = STOPWORDS\n",
    "custom_sps = set(['made', 'nothing','able', 'given', 'wish', 'willing', 'wa', 'due', 'ha', 'did','etc', 'use', 'really', 'felt', 'personally', 'also', 'thing', 'well', 'little', 'got', 'one', 'lot', 'way', 'jus', 'sure'])\n",
    "cust_nltk_sw = set(stopwords.words('english')).union(custom_sps).union(wc_sw)\n",
    "print(f'The number of stop words in custom list is: {len(cust_nltk_sw)}')\n",
    "\n",
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_id = title_df.ID\n",
    "nbr_features = len(title_df.ID)\n",
    "\n",
    "fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "df0=title_df['lemm_tokens']\n",
    "text = convert_text(df0)\n",
    "cloud = WordCloud(background_color=\"white\", max_words=10, stopwords=cust_nltk_sw, collocations=False).generate(text)\n",
    "\n",
    "plt.imshow(cloud, interpolation='bilinear')\n",
    "plt.title(title_df.ID.values, fontsize = 20)\n",
    "plt.axis('off')\n",
    "plt.savefig(f\"{author_id}_wordcloud.png\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47389e9",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f8471",
   "metadata": {},
   "source": [
    "<h1>Create new DataFrame for Displaying WordCloud Images</h1>\n",
    "\n",
    " - Concatenate author_titles and titles\n",
    " - Add column for url\n",
    " - Add url\n",
    " - Export as CSV for tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [title_df, author_titles]\n",
    "word_cloud_df = pd.concat(frames, ignore_index=True)\n",
    "word_cloud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_lists = ['https://i.imgur.com/NGDC7RA.png','https://i.imgur.com/HE8dkGa.png','https://i.imgur.com/EtQDWsW.png', 'https://i.imgur.com/bxm8T6x.png', 'https://i.imgur.com/2Gch9y0.png','https://imgur.com/YlKbGz8', 'https://i.imgur.com/UzCst7H.png']\n",
    "word_cloud_df[\"urls\"] = url_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19adf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_df.to_csv(\"id_wordclouds.csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8451f8ce",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px solid black;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b83ee88",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3881721734.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/0d/xqmptt6x035b25m88r2ffc9m0000gn/T/ipykernel_2829/3881721734.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <h1>Network Analysis</h1>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h1>Network Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6768643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Build a dataframe with your connections\n",
    "df = pd.DataFrame({ 'from':['A', 'B', 'C','A'], 'to':['D', 'A', 'E','C']})\n",
    " \n",
    "# Build your graph\n",
    "G=nx.from_pandas_edgelist(df, 'from', 'to')\n",
    " \n",
    "# Chart with Custom edges:\n",
    "nx.draw(G, with_labels=True, width=5, edge_color=\"skyblue\", style=\"solid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88671413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your graph\n",
    "G=nx.from_pandas_edgelist(df, 'from', 'to')\n",
    " \n",
    "# Chart with Custom edges:\n",
    "nx.draw(G, with_labels=True, width=5, edge_color=\"skyblue\", style=\"solid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
