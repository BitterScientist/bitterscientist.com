<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <title>Machine Learning & Real Estate</title>
  <!-- Bootstrap -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>


  <!-- Import mapping dependencies -->
  <link rel="stylesheet" href="https://unpkg.com/leaflet@1.4.0/dist/leaflet.css" />
  <script src="https://unpkg.com/leaflet@1.4.0/dist/leaflet.js"></script>
  <!-- Styling module -->
  <link rel="stylesheet" type="text/css" href='projects/la_weapon_crimes/static/css/map.css' )>

  <!-- Navbar -->
  <link rel="stylesheet" type="text/css" href='../../static/css/navbar.css' )>

  <!-- Footer -->
  <link rel="stylesheet" type="text/css" href='../../static/css/footer.css' )>

  <!-- General Themes -->
  <link rel="stylesheet" type="text/css" href='../../static/css/theme.css' )>
  <link rel="stylesheet" type="text/css" href='../../static/css/general_landing.css' )>
  <link rel="stylesheet" type="text/css" href='../../static/css/post-table.css' )>
  <link rel="stylesheet" type="text/css" href='../../static/css/code_blocks.css' )>
</head>


<body>
  <div id="page-container">
    <div id="content-wrap">
      <div w3-include-html="/folders/navbar_footer/navbar_pages.html"></div>


      <!-- all other page content -->
      <!-- Webpage title -->
      <div class="title">
        <h1>Model Californian Housing Prices using Python and Machine Learning</h1>
      </div>

      <!-- Last updated -->
      <!-- Last updated -->
      <div class="date_updated">
        <p class="post-timestamp">First Posted: 2-12-2020<br>
          Last Updated: 2-12-2020</p>
      </div>

      <!-- Main container for the subfield -->
      <main class="sub-container">

        <!-- Sets up bootstrap - this page only has one row -->
        <div class="row">

          <!-- The first column of this row is size 4 - the background panel -->
          <div class="col-sm-12">

            <!-- Side panel container for background information -->
            <div class="background-panel">
              <div class="caption">
                <p>Background Info</p>
              </div>
              <div class="background-info">
                <!-- <img src="" alt="html"
                  class="background-pic" width="125" height="150"> -->
                <div class="background-img-caption">
                  <p></p>
                </div>
                <p class="general-p">
                  <B>Machine Learning in Real Estate</B> <br>
                  Comparative market analysis (CMA) is used to estimate the value of a home. This figure helps sellers
                  chose their asking price, and it helps buyers evaluate this price. The CMA is determined by recently
                  sold, and active listings that are comparable to the home that will be listed in the market. Creating
                  an actual CMA also takes into account: <br>
                  <ul>
                    <li>Neighborhood 'quality'</li>
                    <li>Home features: age, number of bedrooms, rooms, house condition, potential issues, and recent
                      upgrades</li>
                    <li>CMAs produced by other estimators (Zillow, HouseCanary)</li>
                    <li>CMAs of other homes in area</li>
                    <li>CMAs of comparable homes in other neighborhoods</li>
                    <li>CMAs of homes with similar lot features</li>
                  </ul>
                </p>
                <p class="general-p"><strong>Why is this important?</strong><br>
                  Since there are so many factors that can be considered in the calculation of a CMA, the algorithms
                  that are used can be complex, and resource intensive. To complicate matters, algorithms used in one
                  real estate appraisal system may vary across platforms, making it difficult to agree on an actual CMA.
                  Therefore there is a need for an advance computational method to estimate an CMA using large dataset
                  that take into account neighborhood, median housing prices, population, and housing features. This is
                  where machine learning can play an important role. Learning how to deploy various models to estimate
                  CMAs is an important practice for an ML ninja.
                </p>
                <p class="general-p"><strong>The project goal</strong><br>
                  Given the rational stated above, the goal of this project is to use three different supervised machine learning models 
                  to estimate the median housing price (CMA) for homes in California, and determine which of these three perform the best.
                </p>
              </div>
              <div class="resources">
                <div class="sub-title">
                  <h4>Resources & Citations</h4>
                </div>
                <ul class="resources-ul">
                  <li><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/"
                      target="_blank">1. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd
                      Edition, by Aurelien Geron (O'Rilley). 2019 Kiwisoft SAS, 978-1-492-03264-9</a>
                  </li>
                  <li><a href="https://github.com/ageron/handson-ml2/tree/master/datasets/housing" target="_blank">2.
                      Data obtained from Handson-ml2, by Aurelien Geron.</a> Dataset modified from R. Kelley Pace and
                    Ronald Barry, "Sparse Spacial Autoregression," Statistics and Probability Letters 33, no. 3 (1997):
                    291-297
                  </li>
                </ul>
              </div>
            </div>



            <!-- OLD COLUMN 4 CLOSING DIV -->
            <!-- </div> -->


            <!-- SECOND COLUMN WITH MAIN CONTENT -->
            <!-- <div class="col-sm-8"> -->
            <div class="sub-section">
              <center>
                <a href="projects/housing_pricing/housing.ipynb" download>Download Jupyter Notebook File</a>
              </center>
              <div class="table_of_contents">
                <p class="content-list">
                  <center>
                    <h4>Research Objectives</h4>
                  </center>
                  <ol>
                    <li><a href="#objective1">Visualize Geographical Data</a></li>
                    <li><a href="#objective2">Exploratory Data Analysis</a></li>
                    <li><a href="#objective3">Prepare Data for ML Algorithms</a></li>
                    <li><a href="#objective4">Linear Regression Model</a></li>
                    <li><a href="#objective5">Support Vector Machine Regressor</a></li>
                    <li><a href="#objective6">Ensemble Learning with RandomForestRegression</a></li>
                  </ol>
                </p>
              </div>
              <hr class="sec-div">
              <p class="sub-title">
                <h4>Methods</h4>
              </p>
              <div id="methods">
                <p class="general-p">
                  <strong><em>Data</em></strong>
                  <br>
                  The dataset is a modification of Pace and Berry (1997), and consists of 10 features, and 20640
                  instances, each representing a 1990 Californian census block. The features in this dataset include:
                  geographical coordinates (lat, lng, proximity to the ocean), housing features (rooms, bedrooms, median
                  value), and census information (median age, population, median income). The target in this dataset is
                  the house value.
                </p>
                <hr>
                <p class="general-p">
                  <strong><em>Analysis</em><br></strong>
                  The programming language Python was used in this project. Data was loaded and manipulated using the
                  pandas library. The matplotlib and seaborn libraries were used to visualize data. The scipy, and
                  sklearn libraries
                  were used in the machine learning models.
                </p>
                <hr>
                <p class="general-p">
                  <strong><em>Objective</em></strong><br>
                  The goal of this project is to build a machine learning model that is able to predict the median
                  housing prices for California during the 1990s.
                  <br>
                </p>
              </div>
              <hr class="sec-div">
              <p class="sub-title">
                <h4>Results:
                </h4>
              </p>
              <div id="objective1">
                <p class="general-p">
                  <strong><em>Households with high median value cluster around areas of the Californian coast.</em></strong><br>
                  &emsp;&emsp;&emsp;&emsp;To build a supervised machine learning model to predict the Comparative market analysis (CMA) of a house in a given area requires a known dataset.  This known dataset is used to train an algorithm to would learn patters within the dataset that enables it to classify your target of interest.  To this end, the 1990's census data was used to build a machine learning model.  This dataset consists of 10 features: latitude, longitude, housing median age, total rooms, total bedrooms, population, households, median income, median house value, and ocean proximity.  Of these features, the median household value is considered our target feature, as this is what we intend to classify (predict).  The other features in this dataset will be referred to as the predictor features, as they will be used to train our model.<br>
                </p>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure1.png">
                  <img src="projects/housing_pricing/static/images/figure1.png" width="60%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 1.</strong> 1990 US Census Californian Housing Price.
                </p>
                <hr>

              </div>

              <div id="objective2">
                <p class="general-p">
                  <strong><em>Exploratory Data Analysis (EDA).</em></strong><br>
                  &emsp;&emsp;&emsp;&emsp;Before building a model, it's important to conduct exploratory data analysis in order to assess if any predictors associate with the target variable. In figure 1, we see that the median house value tends to cluster along coastal cities, and we can surmise that the ocean proximity feature may be important, just like the latitude and longitude.<br>
                  &emsp;&emsp;&emsp;&emsp;The next step is to evaluate the numeric features in the dataset, and we see in figure 2 that:
                  <ul>
                    <li>The features have different scales.</li>
                    <li>There are high peaks in the housing median age and median house value columns, which suggest that the data itself was capped, and will create an issue with any model we build as the algorithm will assume housing values do not exceed the cap.</li>
                    <li>The features do not follow a normal distribution (they are tail heavy), which makes it harder for an algorithm to recognize patterns.</li>
                    We need to keep these features in mind as we build a model moving forward.
                  </ul>
                </p>
                <p class="general-p">
                  The next step in the EDA is to examine the correlation between various pairs of attributes in this dataset.  This was accomplished using a scatter matrix for the numeric attributes house value, income, rooms, and age.  In figure 3 we see that only median house value and median income of an area has a visible association, while the others do not.  The pearson's r was calculated for these attributes and plotted for comparison. We see in figure 4 that latitude, longitude, and population have a negative Pearson's r value, while bedrooms, households, age, rooms, and income have a positive Pearson's r value. Moreover, we see that the Pearson's R value for median income is nearly 69%, and we can anticipate that this feature may play an important role in the training of our machine learning model.<br>
                  &emsp;&emsp;&emsp;&emsp;Finally, before preparing the data for machine learning, it would be helpful to engineer new features that aren't in the dataset, but may be helpful.  This can be performed by creating new features  by performing some mathematical operation between existing features. For example, if we can assume that higher valued houses are in areas where there more than people, we can divide rooms by population, and create a new column.  This strategy was then used to engineer the following features: rooms per people, rooms per households, people per household, people per room, and bedrooms per room. When we plot the Pearson's R for for these new attributes (Figure 5), we see that as predicted, rooms per people and rooms per household were positively correlation with the median house value, while bedrooms per room, people per room, and people per household were negatively correlated.  Bottom line, we can conclude that richer people live with less people, and will have more space (more rooms), and will spend more on a house.
                </p>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure2.png">
                  <img src="projects/housing_pricing/static/images/figure2.png" width="75%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 2.</strong>Frequency distribution for numeric attributes in dataset.
                </p>
                <hr>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure4.png">
                  <img src="projects/housing_pricing/static/images/figure4.png" width="60%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 3.</strong> Scatter plot matrix for median age, income, house
                  value, and total rooms.
                </p>
                <hr>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure3.png">
                  <img src="projects/housing_pricing/static/images/figure3.png" width="60%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 4.</strong> Correlation of features to median housing value.
                </p>
                <hr>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure5.png">
                  <img src="projects/housing_pricing/static/images/figure5.png" width="70%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 5.</strong> Correlation of engineered features to median housing
                  value.
                </p>
                <hr>

                <!-- END OF OBJ2 DIV -->
              </div>
              <hr>

              <div id="objective3">
                <p class="general-p">
                  <strong><em>Prepare Data for ML Algorithms.</em></strong><br>
                  &emsp;&emsp;&emsp;&emsp;During the exploratory data analysis we noticed that the features were on different scales, and were not normally distributed (bell shaped).  Before we can proceed build a machine learning model, the data must be wrangled, and transformed.  The wrangling involved replacing missing values, and converting the categorical feature "Ocean Proximity" into a numeric field. The features are then scaled so that they are all approximately within the same numeric range.  To this end, a transformation pipeline was used to conduct this in one step.  SimpleImputer and StandardScaler were used to fill in missing values and then scale the numeric data, while OneHotEncoder was used to convert the categorical column into a numeric field.  Figure 6 demonstrates the transformation of the features as box plots. Notice that each feature's range lies within -2 to 3.
                </p>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure6.png">
                  <img src="projects/housing_pricing/static/images/figure6.png" width="50%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 6.</strong> Distribution of data for features post feature scaling.
                </p>
              </div>
              <hr>

              <div id="objective4">
                <p class="general-p">
                  <strong><em>Linear Regression Model.</em></strong><br>
                  &emsp;&emsp;&emsp;&emsp;The Linear Regression model is the first algorithm we test, as it is the simplest, and most classic of the regression types.  The root mean squared error (RMSE) was used as the performance measures in this model.  The RMSE was $68,628, which is a high value, given that the range of house values is between $120,000 to $265,000. This value suggest that the model is under, and that we may not have enough features to provide the algorithm sufficient information to make better predictions.<br>
                  &emsp;&emsp;&emsp;&emsp;When we plot the actual median values to the predicted median value (Figure 7), we see can see the impact of the household value cap, as there is a line at the top of the plot.  Furthermore, if the RMSE was closer to 0, we would expect the cluster of points to convert closer to a line, the fact that the scatter is more diffused, provides additional support that the model is underfit.
                </p>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure7.png">
                  <img src="projects/housing_pricing/static/images/figure7.png" width="50%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 7.</strong> Association between the linear regression predicted median household value and the actual median household value.
                </p>
                <hr>
              </div>

              <hr>
              <div id="objective5">
                <p class="general-p">
                  <strong><em>Support Vector Machine Regressor</em></strong><br>
                  &emsp;&emsp;&emsp;&emsp;Since not all relationships are linear, it is important to test models that can detect patterns in complex nonlinear relationships in a dataset. The root mean squared error (RMSE) for this model was $111,094, which confirmed that this model performed more poorly than the Linear Regression model.  This was in the scatter plot comparing the actual median house value to the predicted median house value in Figure 8. In this plot we see that the data is more diffuse than in Figure 7.
                </p>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure8.png">
                  <img src="projects/housing_pricing/static/images/figure8.png" width="50%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 8.</strong> Association between the Support Vector Regression predicted median household value and the actual median household value.
                </p>
              </div>


              <hr>

              <div id="objective6">
                <p class="general-p">
                  <strong><em>Ensemble Learning with RandomForestRegression.</em></strong><br>
                  &emsp;&emsp;&emsp;&emsp;The final model used in this post is an ensemble method, which combines several models that perform the best.  In this approach, I used GridSearchCV and RandomForestRegression to build a predictive algorithm. GridSearchCV identifies the optimal hyperparameters, while RandomForestRegression is a method that trains many Decision Trees and averages out their predictions.  By using this ensembled approach, the RMSE for this models was $49,660, this is an improvement over the Linear Regression model which has an RMSE of $68,628. The improvement in this model was also evident in the Figure 9, where we compare the predicted to the actual median house value.  The scatter plot was less diffuse than the plots for the other models.<br>
                  &emsp;&emsp;&emsp;&emsp;The feature importance scores were plotted to determine which features are important in this model.  We see in Figure 10 that the median income remains the most important predictor (~0.33), followed by the geographic category "Near Ocean".  Figure 1 did reveal that coastal regions had a high density of expensive houses, and this analysis supports that observation.<br>
                  &emsp;&emsp;&emsp;&emsp; Finally, although the model performed well on the training dataset, we need to evaluate its performance on test data. When we carry out this analysis we see that the RMSE is $47,972, slightly better than the training dataset, while the scatter plot in Figure 11 resembles the scatter plot for the test set, although slightly more diffuse.
                </p>
                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure9.png">
                  <img src="projects/housing_pricing/static/images/figure9.png" width="50%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 9.</strong> Association between the Random Forest Regression predicted median household value and the actual median household value.
                </p>
                <hr>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure10.png">
                  <img src="projects/housing_pricing/static/images/figure10.png" width="70%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 10.</strong> Feature importance scores.
                </p>
                <hr>

                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure11.png">
                  <img src="projects/housing_pricing/static/images/figure11.png" width="50%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 11.</strong> Association between the Cross-Validated Random Forest Regression predicted median household value and the actual median household value.
                </p>

              </div>

              <hr>
              <div id="objective7">
                <p class="general-p">
                  <strong><em>Ensemble methods using RandomForestRegression outperforms Linear Regression and Support Vector Regression Machine Learning models.</em></strong><br>
                  &emsp;&emsp;&emsp;&emsp; In this post, we explored three different supervised learning algorithms. These models were trained used the 1990s US Census data to 
                  predict the median house value.  The goal of this project was to use this model, and this dataset, as a proof of principle in comparative market analysis.  Current methods used to estimate the price of house can be daunting, and can vary depending on the factors used to arrive at this value.  Machine learning on the other hand provides an approach that is both scalable, and reproducible.  In this study we test linear regression, support vector regression, and random forest regression algorithms.  We determined that the RandomForestRegression method, as part of an ensemble strategy, had the best measure of performance (The Root Mean Squared Error (RMSE)), than the other models tested.  Although the RMSE was still a 95% confidence interval (data not shown), the prediction was still off by about 20%.  I would argue that this estimate is not bad given the small number of features used in this analysis. Instead, this post highlights the utility of machine learning in automating complex calculation that can help sellers, and buyers make transactions grounded on advance, and readily available methods. In fact, this model can only be improved by adding additional meaningful predictors, reminding us that machine learning is not only powerful, but flexible.
                <!-- Figure -->
                <a href="projects/housing_pricing/static/images/figure12.png">
                  <img src="projects/housing_pricing/static/images/figure12.png" width="50%" height=100%
                    class="figure"></img></a>
                <p class="figure_title"><strong>Figure 12.</strong> Comparison of model performance in predicting median house values.
                </p>
                </p>
              </div>

              <!-- ################################ TEMPLATES ########################## -->


              <!-- Figure template -->
              <!-- <a href="projects/">
                <img src="projects/" width="100%" height=100% class="figure"></img></a>
              <p class="figure_title"><strong>Figure 1. </strong>
              </p> -->

              <!-- Table template -->
              <!-- <p class="table_title"><strong>Table 1. </strong> Table title<br>
              </p>
              <a href="projects/">
                <img src="projects/" width="75%" height=100% class="table_img"></img></a> -->


              <!-- CLOSING DIV FOR SUB-SECTION -->
            </div>


            <!-- ################################ DO NOT ENTER ########################## -->
            <div class="sub-entry">
              <div w3-include-html="ds_blogs_table.html"></div>
            </div>
          </div>
          <!-- Div for the bootstrap row -->
        </div>
        <!-- CLOSING MAIN -->
      </main>
      <!-- CLOSING DIV FOR CONTENT-WRAPPER -->
    </div>
    <!--This div for footer-page div-->
    <div w3-include-html="/folders/navbar_footer/footer.html"></div>
    <!-- CLOSING DIV FOR PAGE-CONTAINER -->
  </div>

  <!-- THESE ARE KEY FOR THE D3JS -->
  <script src="https://d3js.org/d3.v5.min.js"></script>
  <!-- THIS IS TO ADD THE HEADER AND FOOTER -->
  <script type="text/javascript" src="../../static/js/include.js"></script>
  <!-- Mapping js -->
  <script type="text/javascript" src="projects/la_weapon_crimes/static/js/mapping.js"></script>
</body>

</html>